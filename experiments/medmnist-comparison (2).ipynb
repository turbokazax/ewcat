{"metadata":{"colab":{"provenance":[],"toc_visible":true,"collapsed_sections":["jvk5kVGHMLH7","BK4jvloHMSSD","RMcBOv1RaNwm","zyG8uB1Ips_m","jTr9R-_g0qFB"],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Ins","metadata":{}},{"cell_type":"code","source":"!pip install medmnist\n!pip install albumentations\n!pip install torchmetrics\n!pip install transformers datasets evaluate accelerate pillow torchvision scikit-learn\nimport os\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nimport pandas as pd\nimport numpy as np\n#import matplotlib\nimport matplotlib.pyplot as plt\nfrom torch.utils.data import Dataset, DataLoader\nfrom tqdm import tqdm\nfrom torchvision import models\n# from torchmetrics.classification import BinaryF1Score\nfrom medmnist import PneumoniaMNIST\nprint(\"Imported PneumoniaMNIST\")","metadata":{"execution":{"iopub.status.busy":"2024-09-20T14:54:26.779948Z","iopub.execute_input":"2024-09-20T14:54:26.780910Z","iopub.status.idle":"2024-09-20T14:55:17.772994Z","shell.execute_reply.started":"2024-09-20T14:54:26.780869Z","shell.execute_reply":"2024-09-20T14:55:17.771912Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: medmnist in /opt/conda/lib/python3.10/site-packages (3.0.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from medmnist) (1.26.4)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from medmnist) (2.2.2)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from medmnist) (1.2.2)\nRequirement already satisfied: scikit-image in /opt/conda/lib/python3.10/site-packages (from medmnist) (0.23.2)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from medmnist) (4.66.4)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from medmnist) (9.5.0)\nRequirement already satisfied: fire in /opt/conda/lib/python3.10/site-packages (from medmnist) (0.6.0)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from medmnist) (2.4.0)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from medmnist) (0.19.0)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from fire->medmnist) (1.16.0)\nRequirement already satisfied: termcolor in /opt/conda/lib/python3.10/site-packages (from fire->medmnist) (2.4.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->medmnist) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->medmnist) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->medmnist) (2024.1)\nRequirement already satisfied: scipy>=1.9 in /opt/conda/lib/python3.10/site-packages (from scikit-image->medmnist) (1.14.0)\nRequirement already satisfied: networkx>=2.8 in /opt/conda/lib/python3.10/site-packages (from scikit-image->medmnist) (3.3)\nRequirement already satisfied: imageio>=2.33 in /opt/conda/lib/python3.10/site-packages (from scikit-image->medmnist) (2.34.1)\nRequirement already satisfied: tifffile>=2022.8.12 in /opt/conda/lib/python3.10/site-packages (from scikit-image->medmnist) (2024.5.22)\nRequirement already satisfied: packaging>=21 in /opt/conda/lib/python3.10/site-packages (from scikit-image->medmnist) (21.3)\nRequirement already satisfied: lazy-loader>=0.4 in /opt/conda/lib/python3.10/site-packages (from scikit-image->medmnist) (0.4)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->medmnist) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->medmnist) (3.5.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->medmnist) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch->medmnist) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->medmnist) (1.13.2)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->medmnist) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->medmnist) (2024.6.1)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=21->scikit-image->medmnist) (3.1.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->medmnist) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->medmnist) (1.3.0)\nRequirement already satisfied: albumentations in /opt/conda/lib/python3.10/site-packages (1.4.14)\nRequirement already satisfied: numpy>=1.24.4 in /opt/conda/lib/python3.10/site-packages (from albumentations) (1.26.4)\nRequirement already satisfied: scipy>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from albumentations) (1.14.0)\nRequirement already satisfied: scikit-image>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from albumentations) (0.23.2)\nRequirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from albumentations) (6.0.2)\nRequirement already satisfied: typing-extensions>=4.9.0 in /opt/conda/lib/python3.10/site-packages (from albumentations) (4.12.2)\nRequirement already satisfied: pydantic>=2.7.0 in /opt/conda/lib/python3.10/site-packages (from albumentations) (2.8.2)\nRequirement already satisfied: albucore>=0.0.13 in /opt/conda/lib/python3.10/site-packages (from albumentations) (0.0.13)\nRequirement already satisfied: eval-type-backport in /opt/conda/lib/python3.10/site-packages (from albumentations) (0.2.0)\nRequirement already satisfied: opencv-python-headless>=4.9.0.80 in /opt/conda/lib/python3.10/site-packages (from albumentations) (4.10.0.84)\nRequirement already satisfied: tomli>=2.0.1 in /opt/conda/lib/python3.10/site-packages (from albucore>=0.0.13->albumentations) (2.0.1)\nRequirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic>=2.7.0->albumentations) (0.7.0)\nRequirement already satisfied: pydantic-core==2.20.1 in /opt/conda/lib/python3.10/site-packages (from pydantic>=2.7.0->albumentations) (2.20.1)\nRequirement already satisfied: networkx>=2.8 in /opt/conda/lib/python3.10/site-packages (from scikit-image>=0.21.0->albumentations) (3.3)\nRequirement already satisfied: pillow>=9.1 in /opt/conda/lib/python3.10/site-packages (from scikit-image>=0.21.0->albumentations) (9.5.0)\nRequirement already satisfied: imageio>=2.33 in /opt/conda/lib/python3.10/site-packages (from scikit-image>=0.21.0->albumentations) (2.34.1)\nRequirement already satisfied: tifffile>=2022.8.12 in /opt/conda/lib/python3.10/site-packages (from scikit-image>=0.21.0->albumentations) (2024.5.22)\nRequirement already satisfied: packaging>=21 in /opt/conda/lib/python3.10/site-packages (from scikit-image>=0.21.0->albumentations) (21.3)\nRequirement already satisfied: lazy-loader>=0.4 in /opt/conda/lib/python3.10/site-packages (from scikit-image>=0.21.0->albumentations) (0.4)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=21->scikit-image>=0.21.0->albumentations) (3.1.2)\nRequirement already satisfied: torchmetrics in /opt/conda/lib/python3.10/site-packages (1.4.1)\nRequirement already satisfied: numpy>1.20.0 in /opt/conda/lib/python3.10/site-packages (from torchmetrics) (1.26.4)\nRequirement already satisfied: packaging>17.1 in /opt/conda/lib/python3.10/site-packages (from torchmetrics) (21.3)\nRequirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from torchmetrics) (2.4.0)\nRequirement already satisfied: lightning-utilities>=0.8.0 in /opt/conda/lib/python3.10/site-packages (from torchmetrics) (0.11.6)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from lightning-utilities>=0.8.0->torchmetrics) (70.0.0)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>17.1->torchmetrics) (3.1.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->torchmetrics) (3.15.1)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->torchmetrics) (1.13.2)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->torchmetrics) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->torchmetrics) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->torchmetrics) (2024.6.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->torchmetrics) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->torchmetrics) (1.3.0)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.44.0)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.21.0)\nRequirement already satisfied: evaluate in /opt/conda/lib/python3.10/site-packages (0.4.3)\nRequirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.33.0)\nRequirement already satisfied: pillow in /opt/conda/lib/python3.10/site-packages (9.5.0)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (0.19.0)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (1.2.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.15.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.24.6)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.4)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.19.1)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (16.1.0)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.2.2)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.5)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\nRequirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.4.0)\nRequirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.14.0)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (3.5.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.7.4)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.13.2)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\nImported PneumoniaMNIST\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# LeViT-384","metadata":{}},{"cell_type":"code","source":"import os\nimport torch\nfrom torch.utils.data import DataLoader\nfrom torch.optim import AdamW\nfrom torch.nn import CrossEntropyLoss\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\nfrom transformers import LevitForImageClassification, Trainer, TrainingArguments, EarlyStoppingCallback\nfrom medmnist import PneumoniaMNIST\nfrom torchvision.transforms import v2\nimport numpy as np\nfrom sklearn.metrics import accuracy_score\n\n# Define constants and transformations\nimgnet_mean = [0.485, 0.456, 0.406]\nimgnet_std = [0.229, 0.224, 0.225]\n\ntrain_transform = v2.Compose([\n    v2.CenterCrop(224),\n    v2.RandomHorizontalFlip(p=0.5),\n    v2.RandomVerticalFlip(p=0.5),\n    v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)]),\n    v2.Normalize(imgnet_mean, imgnet_std)\n])\n\nval_test_transform = v2.Compose([\n    v2.CenterCrop(224),\n    v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)]),\n    v2.Normalize(imgnet_mean, imgnet_std)\n])\n\ndef custom_collator(features):\n    # Assuming each feature is a tuple (image_tensor, label) from PneumoniaMNIST\n    images = torch.stack([f[0] for f in features])  # Stack image tensors into a batch\n    labels = np.array([f[1] for f in features])    # Convert labels list to a NumPy array\n    labels = torch.tensor(labels).squeeze(1) if labels.ndim > 1 else torch.tensor(labels)  # Convert to tensor\n    return {'pixel_values': images, 'labels': labels}\n\n# Load datasets\ntrain_dataset = PneumoniaMNIST(split=\"train\", download=True, transform=train_transform, size=224)\nval_dataset = PneumoniaMNIST(split=\"val\", download=True, transform=val_test_transform, size=224)\ntest_dataset = PneumoniaMNIST(split=\"test\", download=True, transform=val_test_transform, size=224)\n\n# Dataloaders\ntrain_loader = DataLoader(\n    train_dataset, \n    batch_size=32, \n    shuffle=True, \n    num_workers=os.cpu_count(), \n    collate_fn=custom_collator\n)\n\nval_loader = DataLoader(\n    val_dataset, \n    batch_size=32, \n    shuffle=False, \n    num_workers=os.cpu_count(), \n    collate_fn=custom_collator\n)\n\ntest_loader = DataLoader(\n    test_dataset, \n    batch_size=32, \n    shuffle=False, \n    num_workers=os.cpu_count(), \n    collate_fn=custom_collator\n)\n\n# Load LeViT model and modify the final classification layer\nmodel = LevitForImageClassification.from_pretrained(\n#     'facebook/levit-128S', \n    'facebook/levit-384',\n    num_labels=2,\n    ignore_mismatched_sizes=True\n)\n\n# Properly replace the classifier layer\nmodel.classifier.linear = torch.nn.Linear(model.classifier.linear.in_features, 2)\n\n# Define class weights\nclass_weights = torch.tensor([1.93904448, 0.67372639], dtype=torch.float).to('cuda')\n\n# Custom loss function to include class weights\ncriterion = CrossEntropyLoss(weight=class_weights)\n\n# Define optimizer\noptimizer = AdamW(model.parameters(), lr=0.001, weight_decay=0.001)\n\n# Define the ReduceLROnPlateau scheduler\nscheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, verbose=True)\n\n# Define training arguments\ntraining_args = TrainingArguments(\n    output_dir='./results',\n    num_train_epochs=50,\n    per_device_train_batch_size=32,\n    per_device_eval_batch_size=32,\n    eval_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    logging_dir='./logs',\n    logging_steps=10,\n    load_best_model_at_end=True,\n    metric_for_best_model=\"eval_loss\",\n    report_to=\"none\"  # Disable W&B logging\n)\n\n# Define accuracy metric function\ndef compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    preds = np.argmax(logits, axis=-1)\n    accuracy = accuracy_score(labels, preds)\n    return {\"accuracy\": accuracy}\n\n# Custom callback to step the scheduler based on validation loss\nclass CustomTrainer(Trainer):\n    def __init__(self, scheduler, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.scheduler = scheduler\n\n    def evaluate(self, eval_dataset=None, **kwargs):\n        eval_output = super().evaluate(eval_dataset, **kwargs)\n        # Use the validation loss to step the scheduler\n        self.scheduler.step(eval_output[\"eval_loss\"])\n        return eval_output\n\n# Create a Trainer instance\ntrainer = CustomTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=val_dataset,\n    tokenizer=None,  # Not used for vision models\n    data_collator=custom_collator,  # Use the custom collator\n    compute_metrics=compute_metrics,  # Add custom metrics function for accuracy\n    optimizers=(optimizer, None),  # Only pass optimizer; scheduler is managed manually\n    callbacks=[EarlyStoppingCallback(early_stopping_patience=10, early_stopping_threshold=0.001)],\n    scheduler=scheduler  # Pass the scheduler to custom trainer\n)\n\n# Train the model\ntrainer.train()\n\n# Evaluate on the test set\nresults = trainer.evaluate(eval_dataset=test_dataset)\nprint(results)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-17T18:57:20.506053Z","iopub.execute_input":"2024-09-17T18:57:20.506379Z","iopub.status.idle":"2024-09-17T19:06:42.145475Z","shell.execute_reply.started":"2024-09-17T18:57:20.506347Z","shell.execute_reply":"2024-09-17T19:06:42.144357Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Using downloaded and verified file: /root/.medmnist/pneumoniamnist_224.npz\nUsing downloaded and verified file: /root/.medmnist/pneumoniamnist_224.npz\nUsing downloaded and verified file: /root/.medmnist/pneumoniamnist_224.npz\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/70.0k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"80b3df5a8016419e84a34157b792b4d2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/158M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"54bed9355b75441481b9c9018174e744"}},"metadata":{}},{"name":"stderr","text":"Some weights of LevitForImageClassification were not initialized from the model checkpoint at facebook/levit-384 and are newly initialized because the shapes did not match:\n- classifier.linear.weight: found shape torch.Size([1000, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n- classifier.linear.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([2]) in the model instantiated\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='3256' max='7400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [3256/7400 08:51 < 11:16, 6.12 it/s, Epoch 22/50]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>Specificity</th>\n      <th>Npv</th>\n      <th>Fpr</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.198000</td>\n      <td>1.373775</td>\n      <td>0.853053</td>\n      <td>0.917112</td>\n      <td>0.881748</td>\n      <td>0.770370</td>\n      <td>0.693333</td>\n      <td>0.229630</td>\n      <td>0.899083</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.157700</td>\n      <td>0.136903</td>\n      <td>0.946565</td>\n      <td>0.959288</td>\n      <td>0.969152</td>\n      <td>0.881481</td>\n      <td>0.908397</td>\n      <td>0.118519</td>\n      <td>0.964194</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.149500</td>\n      <td>0.163870</td>\n      <td>0.935115</td>\n      <td>0.978437</td>\n      <td>0.933162</td>\n      <td>0.940741</td>\n      <td>0.830065</td>\n      <td>0.059259</td>\n      <td>0.955263</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.109500</td>\n      <td>0.160699</td>\n      <td>0.944656</td>\n      <td>0.939024</td>\n      <td>0.989717</td>\n      <td>0.814815</td>\n      <td>0.964912</td>\n      <td>0.185185</td>\n      <td>0.963705</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.080600</td>\n      <td>0.076082</td>\n      <td>0.971374</td>\n      <td>0.979487</td>\n      <td>0.982005</td>\n      <td>0.940741</td>\n      <td>0.947761</td>\n      <td>0.059259</td>\n      <td>0.980745</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.107400</td>\n      <td>0.057997</td>\n      <td>0.977099</td>\n      <td>0.974811</td>\n      <td>0.994859</td>\n      <td>0.925926</td>\n      <td>0.984252</td>\n      <td>0.074074</td>\n      <td>0.984733</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.043000</td>\n      <td>0.070330</td>\n      <td>0.975191</td>\n      <td>0.974747</td>\n      <td>0.992288</td>\n      <td>0.925926</td>\n      <td>0.976562</td>\n      <td>0.074074</td>\n      <td>0.983439</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.051400</td>\n      <td>0.076640</td>\n      <td>0.977099</td>\n      <td>0.992167</td>\n      <td>0.976864</td>\n      <td>0.977778</td>\n      <td>0.936170</td>\n      <td>0.022222</td>\n      <td>0.984456</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>0.056900</td>\n      <td>0.059067</td>\n      <td>0.977099</td>\n      <td>0.992167</td>\n      <td>0.976864</td>\n      <td>0.977778</td>\n      <td>0.936170</td>\n      <td>0.022222</td>\n      <td>0.984456</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>0.025900</td>\n      <td>0.055729</td>\n      <td>0.982824</td>\n      <td>0.992228</td>\n      <td>0.984576</td>\n      <td>0.977778</td>\n      <td>0.956522</td>\n      <td>0.022222</td>\n      <td>0.988387</td>\n    </tr>\n    <tr>\n      <td>11</td>\n      <td>0.060600</td>\n      <td>0.051021</td>\n      <td>0.980916</td>\n      <td>0.992208</td>\n      <td>0.982005</td>\n      <td>0.977778</td>\n      <td>0.949640</td>\n      <td>0.022222</td>\n      <td>0.987080</td>\n    </tr>\n    <tr>\n      <td>12</td>\n      <td>0.081000</td>\n      <td>0.043020</td>\n      <td>0.982824</td>\n      <td>0.987179</td>\n      <td>0.989717</td>\n      <td>0.962963</td>\n      <td>0.970149</td>\n      <td>0.037037</td>\n      <td>0.988447</td>\n    </tr>\n    <tr>\n      <td>13</td>\n      <td>0.048000</td>\n      <td>0.049327</td>\n      <td>0.977099</td>\n      <td>0.984576</td>\n      <td>0.984576</td>\n      <td>0.955556</td>\n      <td>0.955556</td>\n      <td>0.044444</td>\n      <td>0.984576</td>\n    </tr>\n    <tr>\n      <td>14</td>\n      <td>0.025000</td>\n      <td>0.062397</td>\n      <td>0.980916</td>\n      <td>0.987147</td>\n      <td>0.987147</td>\n      <td>0.962963</td>\n      <td>0.962963</td>\n      <td>0.037037</td>\n      <td>0.987147</td>\n    </tr>\n    <tr>\n      <td>15</td>\n      <td>0.356000</td>\n      <td>0.071485</td>\n      <td>0.977099</td>\n      <td>0.992167</td>\n      <td>0.976864</td>\n      <td>0.977778</td>\n      <td>0.936170</td>\n      <td>0.022222</td>\n      <td>0.984456</td>\n    </tr>\n    <tr>\n      <td>16</td>\n      <td>0.060400</td>\n      <td>0.257298</td>\n      <td>0.927481</td>\n      <td>0.911007</td>\n      <td>1.000000</td>\n      <td>0.718519</td>\n      <td>1.000000</td>\n      <td>0.281481</td>\n      <td>0.953431</td>\n    </tr>\n    <tr>\n      <td>17</td>\n      <td>0.033800</td>\n      <td>0.049341</td>\n      <td>0.977099</td>\n      <td>0.972431</td>\n      <td>0.997429</td>\n      <td>0.918519</td>\n      <td>0.992000</td>\n      <td>0.081481</td>\n      <td>0.984772</td>\n    </tr>\n    <tr>\n      <td>18</td>\n      <td>0.017600</td>\n      <td>0.048331</td>\n      <td>0.984733</td>\n      <td>0.987212</td>\n      <td>0.992288</td>\n      <td>0.962963</td>\n      <td>0.977444</td>\n      <td>0.037037</td>\n      <td>0.989744</td>\n    </tr>\n    <tr>\n      <td>19</td>\n      <td>0.014000</td>\n      <td>0.048198</td>\n      <td>0.980916</td>\n      <td>0.989664</td>\n      <td>0.984576</td>\n      <td>0.970370</td>\n      <td>0.956204</td>\n      <td>0.029630</td>\n      <td>0.987113</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>0.111800</td>\n      <td>0.070245</td>\n      <td>0.975191</td>\n      <td>0.979592</td>\n      <td>0.987147</td>\n      <td>0.940741</td>\n      <td>0.962121</td>\n      <td>0.059259</td>\n      <td>0.983355</td>\n    </tr>\n    <tr>\n      <td>21</td>\n      <td>0.033300</td>\n      <td>0.069181</td>\n      <td>0.979008</td>\n      <td>0.989637</td>\n      <td>0.982005</td>\n      <td>0.970370</td>\n      <td>0.949275</td>\n      <td>0.029630</td>\n      <td>0.985806</td>\n    </tr>\n    <tr>\n      <td>22</td>\n      <td>0.011900</td>\n      <td>0.048355</td>\n      <td>0.988550</td>\n      <td>0.987277</td>\n      <td>0.997429</td>\n      <td>0.962963</td>\n      <td>0.992366</td>\n      <td>0.037037</td>\n      <td>0.992327</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [20/20 00:01]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"{'eval_loss': 0.40546631813049316, 'eval_accuracy': 0.8669871794871795, 'eval_precision': 0.828693790149893, 'eval_recall': 0.9923076923076923, 'eval_specificity': 0.6581196581196581, 'eval_npv': 0.9808917197452229, 'eval_fpr': 0.3418803418803419, 'eval_f1': 0.9031505250875146, 'eval_runtime': 1.1131, 'eval_samples_per_second': 560.595, 'eval_steps_per_second': 17.968, 'epoch': 22.0}\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Eff Net b0","metadata":{}},{"cell_type":"code","source":"# model = LevitForImageClassification.from_pretrained(\n#     'facebook/levit-384', \n#     num_labels=2,\n#     ignore_mismatched_sizes=True\n# )\nfrom transformers import EfficientNetForImageClassification\nimport os\nimport torch\nfrom torch.utils.data import DataLoader\nfrom torch.optim import AdamW\nfrom torch.nn import CrossEntropyLoss\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\nfrom transformers import LevitForImageClassification, Trainer, TrainingArguments, EarlyStoppingCallback\nimport medmnist\nfrom medmnist import PneumoniaMNIST\nfrom torchvision.transforms import v2\nimport numpy as np\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n\n\n# Define constants and transformations\nimgnet_mean = [0.485, 0.456, 0.406]\nimgnet_std = [0.229, 0.224, 0.225]\n\ntrain_transform = v2.Compose([\n    v2.CenterCrop(224),\n    v2.RandomHorizontalFlip(p=0.5),\n    v2.RandomVerticalFlip(p=0.5),\n    v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)]),\n    v2.Normalize(imgnet_mean, imgnet_std)\n])\n\nval_test_transform = v2.Compose([\n    v2.CenterCrop(224),\n    v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)]),\n    v2.Normalize(imgnet_mean, imgnet_std)\n])\n\ndef custom_collator(features):\n    # Assuming each feature is a tuple (image_tensor, label) from PneumoniaMNIST\n    images = torch.stack([f[0] for f in features])  # Stack image tensors into a batch\n    labels = np.array([f[1] for f in features])    # Convert labels list to a NumPy array\n    labels = torch.tensor(labels).squeeze(1) if labels.ndim > 1 else torch.tensor(labels)  # Convert to tensor\n    return {'pixel_values': images, 'labels': labels}\n\n# Load datasets\ntrain_dataset = PneumoniaMNIST(split=\"train\", download=True, transform=train_transform, size=224)\nval_dataset = PneumoniaMNIST(split=\"val\", download=True, transform=val_test_transform, size=224)\ntest_dataset = PneumoniaMNIST(split=\"test\", download=True, transform=val_test_transform, size=224)\n\n# Dataloaders\ntrain_loader = DataLoader(\n    train_dataset, \n    batch_size=32, \n    shuffle=True, \n    num_workers=os.cpu_count(), \n    collate_fn=custom_collator\n)\n\nval_loader = DataLoader(\n    val_dataset, \n    batch_size=32, \n    shuffle=False, \n    num_workers=os.cpu_count(), \n    collate_fn=custom_collator\n)\n\ntest_loader = DataLoader(\n    test_dataset, \n    batch_size=32, \n    shuffle=False, \n    num_workers=os.cpu_count(), \n    collate_fn=custom_collator\n)\n\n\nmodel = EfficientNetForImageClassification.from_pretrained(\n    \"google/efficientnet-b0\",\n    num_labels = 2,\n    ignore_mismatched_sizes = True\n)\n# Properly replace the classifier layer\n# model.classifier.linear = torch.nn.Linear(model.classifier.linear.in_features, 2)\nmodel.classifier = torch.nn.Linear(model.classifier.in_features, 2)\n\n# Define class weights\nclass_weights = torch.tensor([1.93904448, 0.67372639], dtype=torch.float).to('cuda')\n\n# Custom loss function to include class weights\ncriterion = CrossEntropyLoss(weight=class_weights)\n\n# Define optimizer\noptimizer = AdamW(model.parameters(), lr=0.001, weight_decay=0.001)\n\n# Define the ReduceLROnPlateau scheduler\nscheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, verbose=True)\n\n# Define training arguments\ntraining_args = TrainingArguments(\n    output_dir='./results',\n    num_train_epochs=50,\n    per_device_train_batch_size=32,\n    per_device_eval_batch_size=32,\n    eval_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    logging_dir='./logs',\n    logging_steps=10,\n    load_best_model_at_end=True,\n    metric_for_best_model=\"eval_loss\",\n    report_to=\"none\",  # Disable W&B logging\n    fp16 = True\n)\n\n# Define the metrics function\ndef compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    preds = np.argmax(logits, axis=-1)\n    \n    # Compute confusion matrix to derive additional metrics\n    tn, fp, fn, tp = confusion_matrix(labels, preds).ravel()\n    \n    # Calculate metrics\n    accuracy = accuracy_score(labels, preds)\n    precision = precision_score(labels, preds, zero_division=0)\n    recall = recall_score(labels, preds, zero_division=0)\n    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0.0  # Specificity\n    npv = tn / (tn + fn) if (tn + fn) > 0 else 0.0  # Negative Predictive Value\n    fpr = fp / (fp + tn) if (fp + tn) > 0 else 0.0  # False Positive Rate\n    f1 = f1_score(labels, preds, zero_division=0)\n    \n    return {\n        \"accuracy\": accuracy,\n        \"precision\": precision,\n        \"recall\": recall,\n        \"specificity\": specificity,\n        \"npv\": npv,\n        \"fpr\": fpr,\n        \"f1\": f1\n    }\n\n# Custom callback to step the scheduler based on validation loss\nclass CustomTrainer(Trainer):\n    def __init__(self, scheduler, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.scheduler = scheduler\n\n    def evaluate(self, eval_dataset=None, **kwargs):\n        eval_output = super().evaluate(eval_dataset, **kwargs)\n        # Use the validation loss to step the scheduler\n        self.scheduler.step(eval_output[\"eval_loss\"])\n        return eval_output\n\n# Create a Trainer instance\ntrainer = CustomTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=val_dataset,\n    tokenizer=None,  # Not used for vision models\n    data_collator=custom_collator,  # Use the custom collator\n    compute_metrics=compute_metrics,  # Add custom metrics function for accuracy\n    optimizers=(optimizer, None),  # Only pass optimizer; scheduler is managed manually\n    callbacks=[EarlyStoppingCallback(early_stopping_patience=10, early_stopping_threshold=0.001)],\n    scheduler=scheduler  # Pass the scheduler to custom trainer\n)\n\n# Train the model\ntrainer.train()\n\n# Evaluate on the test set\nresults = trainer.evaluate(eval_dataset=test_dataset)\nprint(results)","metadata":{"execution":{"iopub.status.busy":"2024-09-20T14:59:39.964851Z","iopub.execute_input":"2024-09-20T14:59:39.965464Z","iopub.status.idle":"2024-09-20T15:08:34.436336Z","shell.execute_reply.started":"2024-09-20T14:59:39.965418Z","shell.execute_reply":"2024-09-20T15:08:34.435292Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Using downloaded and verified file: /root/.medmnist/pneumoniamnist_224.npz\nUsing downloaded and verified file: /root/.medmnist/pneumoniamnist_224.npz\nUsing downloaded and verified file: /root/.medmnist/pneumoniamnist_224.npz\n","output_type":"stream"},{"name":"stderr","text":"Some weights of EfficientNetForImageClassification were not initialized from the model checkpoint at google/efficientnet-b0 and are newly initialized because the shapes did not match:\n- classifier.weight: found shape torch.Size([1000, 1280]) in the checkpoint and torch.Size([2, 1280]) in the model instantiated\n- classifier.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([2]) in the model instantiated\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:488: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='3552' max='7400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [3552/7400 08:48 < 09:33, 6.71 it/s, Epoch 24/50]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>Specificity</th>\n      <th>Npv</th>\n      <th>Fpr</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.060800</td>\n      <td>0.391076</td>\n      <td>0.933206</td>\n      <td>1.000000</td>\n      <td>0.910026</td>\n      <td>1.000000</td>\n      <td>0.794118</td>\n      <td>0.000000</td>\n      <td>0.952894</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.063400</td>\n      <td>1.004356</td>\n      <td>0.895038</td>\n      <td>1.000000</td>\n      <td>0.858612</td>\n      <td>1.000000</td>\n      <td>0.710526</td>\n      <td>0.000000</td>\n      <td>0.923928</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.027000</td>\n      <td>0.036978</td>\n      <td>0.986641</td>\n      <td>0.994819</td>\n      <td>0.987147</td>\n      <td>0.985185</td>\n      <td>0.963768</td>\n      <td>0.014815</td>\n      <td>0.990968</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.036600</td>\n      <td>0.087379</td>\n      <td>0.969466</td>\n      <td>0.965087</td>\n      <td>0.994859</td>\n      <td>0.896296</td>\n      <td>0.983740</td>\n      <td>0.103704</td>\n      <td>0.979747</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.020400</td>\n      <td>0.076709</td>\n      <td>0.982824</td>\n      <td>0.979798</td>\n      <td>0.997429</td>\n      <td>0.940741</td>\n      <td>0.992188</td>\n      <td>0.059259</td>\n      <td>0.988535</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.010900</td>\n      <td>0.065227</td>\n      <td>0.980916</td>\n      <td>1.000000</td>\n      <td>0.974293</td>\n      <td>1.000000</td>\n      <td>0.931034</td>\n      <td>0.000000</td>\n      <td>0.986979</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.043300</td>\n      <td>0.043282</td>\n      <td>0.994275</td>\n      <td>0.994872</td>\n      <td>0.997429</td>\n      <td>0.985185</td>\n      <td>0.992537</td>\n      <td>0.014815</td>\n      <td>0.996149</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.020000</td>\n      <td>3.732732</td>\n      <td>0.868321</td>\n      <td>1.000000</td>\n      <td>0.822622</td>\n      <td>1.000000</td>\n      <td>0.661765</td>\n      <td>0.000000</td>\n      <td>0.902680</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>0.005800</td>\n      <td>0.088474</td>\n      <td>0.984733</td>\n      <td>0.997389</td>\n      <td>0.982005</td>\n      <td>0.992593</td>\n      <td>0.950355</td>\n      <td>0.007407</td>\n      <td>0.989637</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>0.005500</td>\n      <td>0.056866</td>\n      <td>0.990458</td>\n      <td>0.997409</td>\n      <td>0.989717</td>\n      <td>0.992593</td>\n      <td>0.971014</td>\n      <td>0.007407</td>\n      <td>0.993548</td>\n    </tr>\n    <tr>\n      <td>11</td>\n      <td>0.009600</td>\n      <td>2.787889</td>\n      <td>0.864504</td>\n      <td>1.000000</td>\n      <td>0.817481</td>\n      <td>1.000000</td>\n      <td>0.655340</td>\n      <td>0.000000</td>\n      <td>0.899576</td>\n    </tr>\n    <tr>\n      <td>12</td>\n      <td>0.005000</td>\n      <td>0.022322</td>\n      <td>0.992366</td>\n      <td>0.997416</td>\n      <td>0.992288</td>\n      <td>0.992593</td>\n      <td>0.978102</td>\n      <td>0.007407</td>\n      <td>0.994845</td>\n    </tr>\n    <tr>\n      <td>13</td>\n      <td>0.005200</td>\n      <td>0.034097</td>\n      <td>0.990458</td>\n      <td>0.992308</td>\n      <td>0.994859</td>\n      <td>0.977778</td>\n      <td>0.985075</td>\n      <td>0.022222</td>\n      <td>0.993582</td>\n    </tr>\n    <tr>\n      <td>14</td>\n      <td>0.032100</td>\n      <td>0.016849</td>\n      <td>0.992366</td>\n      <td>0.994859</td>\n      <td>0.994859</td>\n      <td>0.985185</td>\n      <td>0.985185</td>\n      <td>0.014815</td>\n      <td>0.994859</td>\n    </tr>\n    <tr>\n      <td>15</td>\n      <td>0.028900</td>\n      <td>1.305178</td>\n      <td>0.896947</td>\n      <td>1.000000</td>\n      <td>0.861183</td>\n      <td>1.000000</td>\n      <td>0.714286</td>\n      <td>0.000000</td>\n      <td>0.925414</td>\n    </tr>\n    <tr>\n      <td>16</td>\n      <td>0.001900</td>\n      <td>0.069260</td>\n      <td>0.988550</td>\n      <td>0.992288</td>\n      <td>0.992288</td>\n      <td>0.977778</td>\n      <td>0.977778</td>\n      <td>0.022222</td>\n      <td>0.992288</td>\n    </tr>\n    <tr>\n      <td>17</td>\n      <td>0.006200</td>\n      <td>0.090630</td>\n      <td>0.980916</td>\n      <td>0.994778</td>\n      <td>0.979434</td>\n      <td>0.985185</td>\n      <td>0.943262</td>\n      <td>0.014815</td>\n      <td>0.987047</td>\n    </tr>\n    <tr>\n      <td>18</td>\n      <td>0.000100</td>\n      <td>0.576518</td>\n      <td>0.961832</td>\n      <td>1.000000</td>\n      <td>0.948586</td>\n      <td>1.000000</td>\n      <td>0.870968</td>\n      <td>0.000000</td>\n      <td>0.973615</td>\n    </tr>\n    <tr>\n      <td>19</td>\n      <td>0.000400</td>\n      <td>4.510524</td>\n      <td>0.872137</td>\n      <td>1.000000</td>\n      <td>0.827763</td>\n      <td>1.000000</td>\n      <td>0.668317</td>\n      <td>0.000000</td>\n      <td>0.905767</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>0.011400</td>\n      <td>0.127060</td>\n      <td>0.975191</td>\n      <td>0.997354</td>\n      <td>0.969152</td>\n      <td>0.992593</td>\n      <td>0.917808</td>\n      <td>0.007407</td>\n      <td>0.983051</td>\n    </tr>\n    <tr>\n      <td>21</td>\n      <td>0.011200</td>\n      <td>0.045661</td>\n      <td>0.990458</td>\n      <td>0.994845</td>\n      <td>0.992288</td>\n      <td>0.985185</td>\n      <td>0.977941</td>\n      <td>0.014815</td>\n      <td>0.993565</td>\n    </tr>\n    <tr>\n      <td>22</td>\n      <td>0.002100</td>\n      <td>0.244216</td>\n      <td>0.963740</td>\n      <td>1.000000</td>\n      <td>0.951157</td>\n      <td>1.000000</td>\n      <td>0.876623</td>\n      <td>0.000000</td>\n      <td>0.974967</td>\n    </tr>\n    <tr>\n      <td>23</td>\n      <td>0.001100</td>\n      <td>0.074923</td>\n      <td>0.988550</td>\n      <td>0.992288</td>\n      <td>0.992288</td>\n      <td>0.977778</td>\n      <td>0.977778</td>\n      <td>0.022222</td>\n      <td>0.992288</td>\n    </tr>\n    <tr>\n      <td>24</td>\n      <td>0.008800</td>\n      <td>0.028215</td>\n      <td>0.998092</td>\n      <td>1.000000</td>\n      <td>0.997429</td>\n      <td>1.000000</td>\n      <td>0.992647</td>\n      <td>0.000000</td>\n      <td>0.998713</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [20/20 00:00]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"{'eval_loss': 0.6789042949676514, 'eval_accuracy': 0.8974358974358975, 'eval_precision': 0.8590308370044053, 'eval_recall': 1.0, 'eval_specificity': 0.7264957264957265, 'eval_npv': 1.0, 'eval_fpr': 0.27350427350427353, 'eval_f1': 0.9241706161137441, 'eval_runtime': 0.8577, 'eval_samples_per_second': 727.499, 'eval_steps_per_second': 23.317, 'epoch': 24.0}\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# effnet b7","metadata":{}},{"cell_type":"code","source":"# model = LevitForImageClassification.from_pretrained(\n#     'facebook/levit-384', \n#     num_labels=2,\n#     ignore_mismatched_sizes=True\n# )\n# from transformers import EfficientNetForImageClassification\nfrom transformers import ConvNextForImageClassification\nimport os\nimport torch\nfrom torch.utils.data import DataLoader\nfrom torch.optim import AdamW\nfrom torch.nn import CrossEntropyLoss\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\nfrom transformers import LevitForImageClassification, Trainer, TrainingArguments, EarlyStoppingCallback\nimport medmnist\nfrom medmnist import PneumoniaMNIST\nfrom torchvision.transforms import v2\nimport numpy as np\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n\n\n# Define constants and transformations\nimgnet_mean = [0.485, 0.456, 0.406]\nimgnet_std = [0.229, 0.224, 0.225]\n\ntrain_transform = v2.Compose([\n    v2.CenterCrop(224),\n    v2.RandomHorizontalFlip(p=0.5),\n    v2.RandomVerticalFlip(p=0.5),\n    v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)]),\n    v2.Normalize(imgnet_mean, imgnet_std)\n])\n\nval_test_transform = v2.Compose([\n    v2.CenterCrop(224),\n    v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)]),\n    v2.Normalize(imgnet_mean, imgnet_std)\n])\n\ndef custom_collator(features):\n    # Assuming each feature is a tuple (image_tensor, label) from PneumoniaMNIST\n    images = torch.stack([f[0] for f in features])  # Stack image tensors into a batch\n    labels = np.array([f[1] for f in features])    # Convert labels list to a NumPy array\n    labels = torch.tensor(labels).squeeze(1) if labels.ndim > 1 else torch.tensor(labels)  # Convert to tensor\n    return {'pixel_values': images, 'labels': labels}\n\n# Load datasets\ntrain_dataset = PneumoniaMNIST(split=\"train\", download=True, transform=train_transform, size=224)\nval_dataset = PneumoniaMNIST(split=\"val\", download=True, transform=val_test_transform, size=224)\ntest_dataset = PneumoniaMNIST(split=\"test\", download=True, transform=val_test_transform, size=224)\n\n# Dataloaders\ntrain_loader = DataLoader(\n    train_dataset, \n    batch_size=32, \n    shuffle=True, \n    num_workers=os.cpu_count(), \n    collate_fn=custom_collator\n)\n\nval_loader = DataLoader(\n    val_dataset, \n    batch_size=32, \n    shuffle=False, \n    num_workers=os.cpu_count(), \n    collate_fn=custom_collator\n)\n\ntest_loader = DataLoader(\n    test_dataset, \n    batch_size=32, \n    shuffle=False, \n    num_workers=os.cpu_count(), \n    collate_fn=custom_collator\n)\n\n\n# model = EfficientNetForImageClassification.from_pretrained(\n#     \"google/efficientnet-b7\",\n#     num_labels = 2,\n#     ignore_mismatched_sizes = True\n# )\nmodel = ConvNextForImageClassification.from_pretrained(\n    \"facebook/convnext-tiny-224\",\n    num_labels = 2,\n    ignore_mismatched_sizes = True\n)\n# Properly replace the classifier layer\n# model.classifier.linear = torch.nn.Linear(model.classifier.linear.in_features, 2)\nmodel.classifier = torch.nn.Linear(model.classifier.in_features, 2)\n\n# Define class weights\nclass_weights = torch.tensor([1.93904448, 0.67372639], dtype=torch.float).to('cuda')\n\n# Custom loss function to include class weights\ncriterion = CrossEntropyLoss(weight=class_weights)\n\n# Define optimizer\noptimizer = AdamW(model.parameters(), lr=0.001, weight_decay=0.001)\n\n# Define the ReduceLROnPlateau scheduler\nscheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, verbose=True)\n\n# Define training arguments\ntraining_args = TrainingArguments(\n    output_dir='./results',\n    num_train_epochs=50,\n    per_device_train_batch_size=32,\n    per_device_eval_batch_size=32,\n    eval_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    logging_dir='./logs',\n    logging_steps=10,\n    load_best_model_at_end=True,\n    metric_for_best_model=\"eval_loss\",\n    report_to=\"none\",  # Disable W&B logging\n    fp16 = True\n)\n\n# Define the metrics function\ndef compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    preds = np.argmax(logits, axis=-1)\n    \n    # Compute confusion matrix to derive additional metrics\n    tn, fp, fn, tp = confusion_matrix(labels, preds).ravel()\n    \n    # Calculate metrics\n    accuracy = accuracy_score(labels, preds)\n    precision = precision_score(labels, preds, zero_division=0)\n    recall = recall_score(labels, preds, zero_division=0)\n    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0.0  # Specificity\n    npv = tn / (tn + fn) if (tn + fn) > 0 else 0.0  # Negative Predictive Value\n    fpr = fp / (fp + tn) if (fp + tn) > 0 else 0.0  # False Positive Rate\n    f1 = f1_score(labels, preds, zero_division=0)\n    \n    return {\n        \"accuracy\": accuracy,\n        \"precision\": precision,\n        \"recall\": recall,\n        \"specificity\": specificity,\n        \"npv\": npv,\n        \"fpr\": fpr,\n        \"f1\": f1\n    }\n\n# Custom callback to step the scheduler based on validation loss\nclass CustomTrainer(Trainer):\n    def __init__(self, scheduler, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.scheduler = scheduler\n\n    def evaluate(self, eval_dataset=None, **kwargs):\n        eval_output = super().evaluate(eval_dataset, **kwargs)\n        # Use the validation loss to step the scheduler\n        self.scheduler.step(eval_output[\"eval_loss\"])\n        return eval_output\n\n# Create a Trainer instance\ntrainer = CustomTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=val_dataset,\n    tokenizer=None,  # Not used for vision models\n    data_collator=custom_collator,  # Use the custom collator\n    compute_metrics=compute_metrics,  # Add custom metrics function for accuracy\n    optimizers=(optimizer, None),  # Only pass optimizer; scheduler is managed manually\n    callbacks=[EarlyStoppingCallback(early_stopping_patience=10, early_stopping_threshold=0.001)],\n    scheduler=scheduler  # Pass the scheduler to custom trainer\n)\n\n# Train the model\ntrainer.train()\n\n# Evaluate on the test set\nresults = trainer.evaluate(eval_dataset=test_dataset)\nprint(results)","metadata":{"execution":{"iopub.status.busy":"2024-09-20T16:15:32.513586Z","iopub.execute_input":"2024-09-20T16:15:32.513994Z","iopub.status.idle":"2024-09-20T16:32:50.684452Z","shell.execute_reply.started":"2024-09-20T16:15:32.513959Z","shell.execute_reply":"2024-09-20T16:32:50.682836Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Using downloaded and verified file: /root/.medmnist/pneumoniamnist_224.npz\nUsing downloaded and verified file: /root/.medmnist/pneumoniamnist_224.npz\nUsing downloaded and verified file: /root/.medmnist/pneumoniamnist_224.npz\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/69.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a57fe499cae24e0b8b1417991343b58e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/114M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3aad5859308545058fa6679ff9264755"}},"metadata":{}},{"name":"stderr","text":"Some weights of ConvNextForImageClassification were not initialized from the model checkpoint at facebook/convnext-tiny-224 and are newly initialized because the shapes did not match:\n- classifier.weight: found shape torch.Size([1000, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n- classifier.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([2]) in the model instantiated\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:488: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='2960' max='7400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [2960/7400 17:06 < 25:40, 2.88 it/s, Epoch 20/50]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>Specificity</th>\n      <th>Npv</th>\n      <th>Fpr</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.078300</td>\n      <td>0.240964</td>\n      <td>0.912214</td>\n      <td>0.894253</td>\n      <td>1.000000</td>\n      <td>0.659259</td>\n      <td>1.000000</td>\n      <td>0.340741</td>\n      <td>0.944175</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.079100</td>\n      <td>0.084451</td>\n      <td>0.969466</td>\n      <td>0.969773</td>\n      <td>0.989717</td>\n      <td>0.911111</td>\n      <td>0.968504</td>\n      <td>0.088889</td>\n      <td>0.979644</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.090300</td>\n      <td>0.108530</td>\n      <td>0.954198</td>\n      <td>0.946210</td>\n      <td>0.994859</td>\n      <td>0.837037</td>\n      <td>0.982609</td>\n      <td>0.162963</td>\n      <td>0.969925</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.072200</td>\n      <td>0.124072</td>\n      <td>0.958015</td>\n      <td>0.948655</td>\n      <td>0.997429</td>\n      <td>0.844444</td>\n      <td>0.991304</td>\n      <td>0.155556</td>\n      <td>0.972431</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.068700</td>\n      <td>0.079451</td>\n      <td>0.969466</td>\n      <td>0.972152</td>\n      <td>0.987147</td>\n      <td>0.918519</td>\n      <td>0.961240</td>\n      <td>0.081481</td>\n      <td>0.979592</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.061200</td>\n      <td>0.097826</td>\n      <td>0.967557</td>\n      <td>0.994681</td>\n      <td>0.961440</td>\n      <td>0.985185</td>\n      <td>0.898649</td>\n      <td>0.014815</td>\n      <td>0.977778</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.029900</td>\n      <td>0.075087</td>\n      <td>0.975191</td>\n      <td>0.979592</td>\n      <td>0.987147</td>\n      <td>0.940741</td>\n      <td>0.962121</td>\n      <td>0.059259</td>\n      <td>0.983355</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.042900</td>\n      <td>0.063703</td>\n      <td>0.973282</td>\n      <td>0.974684</td>\n      <td>0.989717</td>\n      <td>0.925926</td>\n      <td>0.968992</td>\n      <td>0.074074</td>\n      <td>0.982143</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>0.036000</td>\n      <td>0.067158</td>\n      <td>0.975191</td>\n      <td>0.992147</td>\n      <td>0.974293</td>\n      <td>0.977778</td>\n      <td>0.929577</td>\n      <td>0.022222</td>\n      <td>0.983139</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>0.030000</td>\n      <td>0.059144</td>\n      <td>0.980916</td>\n      <td>0.984655</td>\n      <td>0.989717</td>\n      <td>0.955556</td>\n      <td>0.969925</td>\n      <td>0.044444</td>\n      <td>0.987179</td>\n    </tr>\n    <tr>\n      <td>11</td>\n      <td>0.037800</td>\n      <td>0.080682</td>\n      <td>0.975191</td>\n      <td>0.970000</td>\n      <td>0.997429</td>\n      <td>0.911111</td>\n      <td>0.991935</td>\n      <td>0.088889</td>\n      <td>0.983523</td>\n    </tr>\n    <tr>\n      <td>12</td>\n      <td>0.010300</td>\n      <td>0.059115</td>\n      <td>0.982824</td>\n      <td>0.982234</td>\n      <td>0.994859</td>\n      <td>0.948148</td>\n      <td>0.984615</td>\n      <td>0.051852</td>\n      <td>0.988506</td>\n    </tr>\n    <tr>\n      <td>13</td>\n      <td>0.022500</td>\n      <td>0.062509</td>\n      <td>0.979008</td>\n      <td>0.977273</td>\n      <td>0.994859</td>\n      <td>0.933333</td>\n      <td>0.984375</td>\n      <td>0.066667</td>\n      <td>0.985987</td>\n    </tr>\n    <tr>\n      <td>14</td>\n      <td>0.012300</td>\n      <td>0.060158</td>\n      <td>0.980916</td>\n      <td>0.997375</td>\n      <td>0.976864</td>\n      <td>0.992593</td>\n      <td>0.937063</td>\n      <td>0.007407</td>\n      <td>0.987013</td>\n    </tr>\n    <tr>\n      <td>15</td>\n      <td>0.006200</td>\n      <td>0.136990</td>\n      <td>0.975191</td>\n      <td>0.970000</td>\n      <td>0.997429</td>\n      <td>0.911111</td>\n      <td>0.991935</td>\n      <td>0.088889</td>\n      <td>0.983523</td>\n    </tr>\n    <tr>\n      <td>16</td>\n      <td>0.008000</td>\n      <td>0.230686</td>\n      <td>0.944656</td>\n      <td>1.000000</td>\n      <td>0.925450</td>\n      <td>1.000000</td>\n      <td>0.823171</td>\n      <td>0.000000</td>\n      <td>0.961282</td>\n    </tr>\n    <tr>\n      <td>17</td>\n      <td>0.002600</td>\n      <td>0.063540</td>\n      <td>0.980916</td>\n      <td>0.997375</td>\n      <td>0.976864</td>\n      <td>0.992593</td>\n      <td>0.937063</td>\n      <td>0.007407</td>\n      <td>0.987013</td>\n    </tr>\n    <tr>\n      <td>18</td>\n      <td>0.015000</td>\n      <td>0.060082</td>\n      <td>0.988550</td>\n      <td>0.989770</td>\n      <td>0.994859</td>\n      <td>0.970370</td>\n      <td>0.984962</td>\n      <td>0.029630</td>\n      <td>0.992308</td>\n    </tr>\n    <tr>\n      <td>19</td>\n      <td>0.022800</td>\n      <td>0.061487</td>\n      <td>0.982824</td>\n      <td>0.997382</td>\n      <td>0.979434</td>\n      <td>0.992593</td>\n      <td>0.943662</td>\n      <td>0.007407</td>\n      <td>0.988327</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>0.002200</td>\n      <td>0.063520</td>\n      <td>0.988550</td>\n      <td>0.989770</td>\n      <td>0.994859</td>\n      <td>0.970370</td>\n      <td>0.984962</td>\n      <td>0.029630</td>\n      <td>0.992308</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [20/20 00:01]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"{'eval_loss': 0.7614489197731018, 'eval_accuracy': 0.8397435897435898, 'eval_precision': 0.7971311475409836, 'eval_recall': 0.9974358974358974, 'eval_specificity': 0.5769230769230769, 'eval_npv': 0.9926470588235294, 'eval_fpr': 0.4230769230769231, 'eval_f1': 0.8861047835990887, 'eval_runtime': 2.1114, 'eval_samples_per_second': 295.545, 'eval_steps_per_second': 9.473, 'epoch': 20.0}\n","output_type":"stream"}]},{"cell_type":"code","source":"!nvidia-smi","metadata":{"execution":{"iopub.status.busy":"2024-09-17T19:40:56.829105Z","iopub.execute_input":"2024-09-17T19:40:56.829482Z","iopub.status.idle":"2024-09-17T19:40:58.002336Z","shell.execute_reply.started":"2024-09-17T19:40:56.829446Z","shell.execute_reply":"2024-09-17T19:40:58.001307Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"},{"name":"stdout","text":"Tue Sep 17 19:40:57 2024       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 550.90.07              Driver Version: 550.90.07      CUDA Version: 12.4     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n| N/A   38C    P0             26W /   70W |   15071MiB /  15360MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n|   1  Tesla T4                       Off |   00000000:00:05.0 Off |                    0 |\n| N/A   42C    P0             27W /   70W |   15093MiB /  15360MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n                                                                                         \n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n+-----------------------------------------------------------------------------------------+\n","output_type":"stream"}]},{"cell_type":"code","source":"!rm -rf /kaggle/working/*","metadata":{"execution":{"iopub.status.busy":"2024-09-20T16:54:16.574663Z","iopub.execute_input":"2024-09-20T16:54:16.575572Z","iopub.status.idle":"2024-09-20T16:54:18.523723Z","shell.execute_reply.started":"2024-09-20T16:54:16.575521Z","shell.execute_reply":"2024-09-20T16:54:18.522696Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# CECT","metadata":{}},{"cell_type":"code","source":"# import albumentations as A\n# from albumentations.pytorch import ToTensorV2\n\nfrom torchvision.transforms import v2\nimport torchvision.transforms.v2.functional as v2f\n\nimgnet_mean = [0.485, 0.456, 0.406]\nimgnet_std = [0.229, 0.224, 0.225]\n\ntrain_transform = v2.Compose([\n    # v2.RandomResizedCrop(224),\n    v2.CenterCrop(224),\n    v2.RandomHorizontalFlip(p = 0.5),\n    v2.RandomVerticalFlip(p = 0.5),\n#     v2.RandomRotation(degrees = 90),\n    # v2.ToDtype(torch.float32, scale=True),\n    v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale = True)]),\n#     v2.GaussianNoise(mean = 0, sigma = 1e-7),\n    v2.Normalize(imgnet_mean, imgnet_std)\n])\n\nempty_transform = v2.Compose([\n    v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale = True)]),\n    # v2.Grayscale(num_output_channels = 3),\n    # v2.Normalize(imgnet_mean, imgnet_std)\n])\n\nval_test_transform = v2.Compose([\n    # v2.Resize(256),\n    v2.CenterCrop(224),\n    # v2.ToDtype(torch.float32, scale=True),\n    v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale = True)]),\n    v2.Normalize(imgnet_mean, imgnet_std)\n])\n\ntrain_batch_size = 32\nvt_batch_size = 32\nnum_workers = os.cpu_count()\n\n# Datasets:\ntrain_dataset = PneumoniaMNIST(\n    split = \"train\",\n    download = True,\n    transform = train_transform,\n    size = 224\n)\n\nval_dataset = PneumoniaMNIST(\n    split = \"val\",\n    download = True,\n    transform = val_test_transform,\n    size = 224\n)\n\ntest_dataset = PneumoniaMNIST(\n    split = \"test\",\n    download = True,\n    transform = val_test_transform,\n    size = 224\n)\n\n# Loaders:\ntrain_loader = DataLoader(\n    train_dataset,\n    batch_size = train_batch_size,\n    shuffle = True,\n    num_workers = num_workers\n)\n\nval_loader = DataLoader(\n    val_dataset,\n    batch_size = vt_batch_size,\n    shuffle = False,\n    num_workers = num_workers\n)\n\ntest_loader = DataLoader(\n    test_dataset,\n    batch_size = vt_batch_size,\n    shuffle = False,\n    num_workers = num_workers\n)\n\n\n\n\nimport torch\nfrom torchvision.models.feature_extraction import create_feature_extractor\nfrom torchvision import models\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass ResNet(torch.nn.Module):\n    def __init__(self):\n        super(ResNet, self).__init__()\n        self.model = models.resnet18(weights='ResNet18_Weights.IMAGENET1K_V1')\n        self.features = torch.nn.Sequential(*list(self.model.children())[:5])\n        self.deconv = torch.nn.Sequential(\n            torch.nn.ConvTranspose2d(64, 16, kernel_size=4, stride=2, padding=1),\n            torch.nn.ReLU(inplace=True),\n            torch.nn.ConvTranspose2d(16, 3, kernel_size=4, stride=2, padding=1),\n        )\n\n    def forward(self, x):\n        for name, param in self.features.named_parameters():\n            param.requires_grad = False\n        x = self.features(x)\n        return self.deconv(x)\n\nclass VGGNet(torch.nn.Module):\n    def __init__(self):\n        super(VGGNet, self).__init__()\n        self.model = models.vgg16(weights='VGG16_Weights.IMAGENET1K_V1')\n        self.features = torch.nn.Sequential(*list(self.model.features.children())[:17])\n        self.deconv = torch.nn.Sequential(\n            torch.nn.Upsample(scale_factor=2, mode='bilinear'),\n            torch.nn.ReLU(inplace=True),\n            torch.nn.ConvTranspose2d(256, 64, kernel_size=4, stride=2, padding=1),\n            torch.nn.ReLU(inplace=True),\n            torch.nn.ConvTranspose2d(64, 3, kernel_size=4, stride=2, padding=1),\n        )\n\n    def forward(self, x):\n        for name, param in self.features.named_parameters():\n            param.requires_grad = False\n        x = self.features(x)\n        return self.deconv(x)\n\nclass MobileNet(torch.nn.Module):\n    def __init__(self):\n        super(MobileNet, self).__init__()\n        self.model = models.mobilenet_v3_large(weights='MobileNet_V3_Large_Weights.IMAGENET1K_V1')\n        self.features = torch.nn.Sequential(*list(self.model.features.children())[:2])\n        self.deconv = torch.nn.Sequential(\n            torch.nn.ConvTranspose2d(16, 3, kernel_size=4, stride=2, padding=1),\n        )\n\n    def forward(self, x):\n        for name, param in self.features.named_parameters():\n            param.requires_grad = False\n        x = self.features(x)\n        return self.deconv(x)\n\n\nclass SwinTransformer(torch.nn.Module):\n    def __init__(self):\n        super(SwinTransformer, self).__init__()\n        self.backbone = models.swin_t(weights='Swin_T_Weights.IMAGENET1K_V1')\n        self.features = create_feature_extractor(self.backbone, return_nodes=['flatten'])\n\n    def forward(self, x):\n        for name, param in self.features.named_parameters():\n            param.requires_grad = False\n        return self.features(x)\n\n\nclass Head(torch.nn.Module):\n    def __init__(self):\n        super(Head, self).__init__()\n        self.mlp_head = torch.nn.Sequential(\n            torch.nn.Linear(768, 2),\n        )\n\n    def forward(self, x):\n        return self.mlp_head(x)\n\n\nclass CECT(torch.nn.Module):\n    def __init__(self):\n        super(CECT, self).__init__()\n        self.vggnet = VGGNet()\n        self.resnet = ResNet()\n        self.mobilenet = MobileNet()\n        self.swin_transformer = SwinTransformer()\n        self.head = Head()\n\n        # # Attention\n        # self.attn_vgg = Attention(256)\n        # self.attn_res = Attention(64)\n        # self.attn_mob = Attention(16)\n\n        # Dimensionality Reduction\n        # self.dimensionality_reduction = DimensionalityReduction(768, 256)\n\n    def forward(self, x, features=False):\n        f_vgg = self.vggnet(x)\n        f_res = self.resnet(x)\n        f_mob = self.mobilenet(x)\n\n        # # attention\n        # f_vgg = self.attn_vgg(f_vgg)\n        # f_res = self.attn_res(f_res)\n        # f_mob = self.attn_mob(f_mob)\n\n        # Combine features\n        inte = (1/3) * f_vgg + (1/3) * f_res + (1/3) * f_mob\n\n        # Dimensionality reduction\n        # inte = self.dimensionality_reduction(inte)\n\n        # Transformer\n        tran_out = self.swin_transformer(inte)\n\n        if features:\n            return tran_out['flatten']\n        else:\n            return self.head(tran_out['flatten'])\n\n\nfrom sklearn.utils.class_weight import compute_class_weight\ntrain_classes =  np.unique(train_dataset.labels)\ntrain_labels = train_dataset.labels.ravel()\nclass_weights = compute_class_weight(class_weight='balanced', classes=train_classes, y=train_labels)\n\nprint(f\"\\n{class_weights}\\n\")\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = CECT().to(device)\n\npytorch_train_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\npytorch_all_params = sum(p.numel() for p in model.parameters())\n\nprint(pytorch_train_params, pytorch_all_params, \"\\n\")\n\n#TRAIN:\n\nimport os\nimport torch\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, roc_curve, auc\n\n# Set up the device (CUDA if available)\n\n\n\n# Set Kaggle working directory for saving model, optimizer, and logs\nkaggle_working_directory = \"/kaggle/working/\"\n\n# Evaluation function\ndef evaluation(true_labels, pred_labels):\n    true_labels = torch.cat(true_labels).cpu().numpy()\n    pred_labels = torch.cat(pred_labels).cpu().numpy()\n\n    tp = ((pred_labels == 1) & (true_labels == 1)).sum()\n    tn = ((pred_labels == 0) & (true_labels == 0)).sum()\n    fp = ((pred_labels == 1) & (true_labels == 0)).sum()\n    fn = ((pred_labels == 0) & (true_labels == 1)).sum()\n\n    accuracy = (tp + tn) / (tp + tn + fp + fn)\n    npv = tn / (tn + fn) if (tn + fn) > 0 else 0.0\n    ppv = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n    sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0.0\n    f1_score = 2 * ppv * sensitivity / (ppv + sensitivity) if (ppv + sensitivity) > 0 else 0.0\n\n    return accuracy, npv, ppv, sensitivity, specificity, f1_score\n\n# Training parameters\nlearning_rate = 1e-3\nmin_lr = 1e-4\nbatch_size = train_batch_size\nnum_epochs = 50\nweight_decay = 1e-3\nalter_lr_patience = 5\nlr_factor = 0.5\nmin_loss = 1e5\n\n# Initialize the optimizer, loss function, and learning rate scheduler\nclass_weights = torch.tensor(class_weights, dtype=torch.float32).to(device)\nloss_func = torch.nn.CrossEntropyLoss(weight=class_weights)\n\noptimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=lr_factor, patience=alter_lr_patience)\n\n# Early stopping logic\nclass EarlyStopper:\n    def __init__(self, patience=10, min_delta=0.001):\n        self.patience = patience\n        self.min_delta = min_delta\n        self.counter = 0\n        self.min_validation_loss = float('inf')\n\n    def early_stop(self, validation_loss):\n        if validation_loss < self.min_validation_loss - self.min_delta:\n            self.min_validation_loss = validation_loss\n            self.counter = 0\n        else:\n            self.counter += 1\n            if self.counter >= self.patience:\n                return True\n        return False\n\n# Instantiate the early stopper\nearly_stopper = EarlyStopper(patience=10, min_delta=0.001)\n\n# Lists to store losses and accuracies for plotting\ntrain_losses = []\nval_losses = []\ntrain_accuracies = []\nval_accuracies = []\n\n# Training loop\nfor epoch in range(num_epochs):\n    t_loss_b, v_loss_b, train_in, val_in = 0, 0, 0, 0\n    t_tle, t_ple, v_tle, v_ple = [], [], [], []\n    print(f'\\nEpoch {epoch + 1}/{num_epochs} \\n' + '-' * 60)\n\n    model.train()\n\n    with tqdm(total=len(train_loader), desc=f\"Training Epoch {epoch + 1}/{num_epochs}\", unit=\"batch\") as pbar:\n        for step, (t_x, t_y) in enumerate(train_loader):\n            t_x, t_y = t_x.to(device), t_y.to(device).squeeze(1)  # Handle (batch_size, 1) shape\n            t_tle.append(t_y)\n            output = model(t_x)\n\n            loss = loss_func(output, t_y.long())  # Ensure t_y is of shape (batch_size,)\n            lab = torch.argmax(output, dim=1)\n            t_ple.append(lab)\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n\n            t_loss_b += loss.item() * t_x.size(0)\n            train_in += t_x.size(0)\n\n            # Update progress bar with loss and accuracy\n            t_acc = (torch.cat(t_ple) == torch.cat(t_tle)).float().mean().item()\n            pbar.set_postfix({\"loss\": f\"{loss.item():.5f}\", \"acc\": f\"{t_acc:.5f}\", \"lr\": scheduler.get_last_lr()})\n            pbar.update(1)\n\n    t_loss = t_loss_b / len(train_loader.dataset)\n    t_acc, t_npv, t_ppv, t_sen, t_spe, t_f1 = evaluation(t_tle, t_ple)\n    train_losses.append(t_loss)\n    train_accuracies.append(t_acc)\n    print(f\"Train loss: {t_loss:.5f}, acc: {t_acc:.5f}, npv: {t_npv:.5f}, ppv: {t_ppv:.5f}, sen: {t_sen:.5f}, spe: {t_spe:.5f}, f1: {t_f1:.5f}\")\n\n    if val_loader is not None:\n        model.eval()\n        with torch.no_grad():\n            with tqdm(total=len(val_loader), desc=f\"Validation Epoch {epoch + 1}/{num_epochs}\", unit=\"batch\") as pbar:\n                for step, (v_x, v_y) in enumerate(val_loader):\n                    v_x, v_y = v_x.to(device), v_y.to(device).squeeze(1)\n                    v_tle.append(v_y)\n                    output = model(v_x)\n\n                    loss = loss_func(output, v_y.long())\n                    lab = torch.argmax(output, dim=1)\n                    v_ple.append(lab)\n                    v_loss_b += loss.item() * v_x.size(0)\n                    val_in += v_x.size(0)\n\n                    v_acc = (torch.cat(v_ple) == torch.cat(v_tle)).float().mean().item()\n                    pbar.set_postfix({\"loss\": f\"{loss.item():.5f}\", \"acc\": f\"{v_acc:.5f}\"})\n                    pbar.update(1)\n\n        v_loss = v_loss_b / len(val_loader.dataset)\n        v_acc, v_npv, v_ppv, v_sen, v_spe, v_f1 = evaluation(v_tle, v_ple)\n        val_losses.append(v_loss)\n        val_accuracies.append(v_acc)\n        print(f\"Val loss: {v_loss:.5f}, acc: {v_acc:.5f}, npv: {v_npv:.5f}, ppv: {v_ppv:.5f}, sen: {v_sen:.5f}, spe: {v_spe:.5f}, f1: {v_f1:.5f}\")\n\n        scheduler.step(v_loss)\n\n        # Early stopping check\n        if early_stopper.early_stop(v_loss):\n            print(f\"Early stopping at epoch {epoch + 1}\")\n            # Save the model upon early stopping\n            model_save_path = os.path.join(kaggle_working_directory, f\"early_stop_model_epoch_{epoch+1}.pth\")\n            optimizer_save_path = os.path.join(kaggle_working_directory, f\"early_stop_optimizer_epoch_{epoch+1}.pth\")\n            torch.save(model.state_dict(), model_save_path)\n            torch.save(optimizer.state_dict(), optimizer_save_path)\n            print(f\"Model saved at {model_save_path}\")\n            break\n\n        # Track the best epoch based on validation loss\n        if v_loss < min_loss:\n            min_loss = v_loss\n            print(f\"New best epoch {epoch + 1}\")\n            # Save the model state and optimizer\n            model_save_path = os.path.join(kaggle_working_directory, f\"best_model_epoch_{epoch+1}.pth\")\n            optimizer_save_path = os.path.join(kaggle_working_directory, f\"best_optimizer_epoch_{epoch+1}.pth\")\n#             if epoch > 15:\n#                 torch.save(model.state_dict(), model_save_path)\n#                 torch.save(optimizer.state_dict(), optimizer_save_path)\n            torch.save(model.state_dict(), model_save_path)\n            torch.save(optimizer.state_dict(), optimizer_save_path)\n\n    else:\n        print(f'Training only. Loss: {t_loss:.5f}, Accuracy: {t_acc:.5f}')\n\nmodel_save_path = os.path.join(kaggle_working_directory, f\"Final_model_epoch_{sepoch+num_epochs}.pth\")\noptimizer_save_path = os.path.join(kaggle_working_directory, f\"Final_optimizer_epoch_{sepoch+num_epochs}.pth\")\n#             if epoch > 15:\ntorch.save(model.state_dict(), model_save_path)\ntorch.save(optimizer.state_dict(), optimizer_save_path)        \n        \n# Plot and save training and validation loss curves\nplt.figure(figsize=(10, 6))\nplt.plot(range(1, len(train_losses) + 1), train_losses, label='Training Loss', color='blue')\nplt.plot(range(1, len(val_losses) + 1), val_losses, label='Validation Loss', color='orange')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.title('Training and Validation Loss')\nplt.legend()\nplt.grid(True)\nplt.savefig(os.path.join(kaggle_working_directory, \"loss_curve.png\"))\nplt.show()\n\n# Plot and save training and validation accuracy curves\nplt.figure(figsize=(10, 6))\nplt.plot(range(1, len(train_accuracies) + 1), train_accuracies, label='Training Accuracy', color='blue')\nplt.plot(range(1, len(val_accuracies) + 1), val_accuracies, label='Validation Accuracy', color='orange')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.title('Training and Validation Accuracy')\nplt.legend()\nplt.grid(True)\nplt.savefig(os.path.join(kaggle_working_directory, \"accuracy_curve.png\"))\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-09-20T16:55:07.082405Z","iopub.execute_input":"2024-09-20T16:55:07.082818Z","iopub.status.idle":"2024-09-20T17:14:34.224220Z","shell.execute_reply.started":"2024-09-20T16:55:07.082779Z","shell.execute_reply":"2024-09-20T17:14:34.222902Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Using downloaded and verified file: /root/.medmnist/pneumoniamnist_224.npz\nUsing downloaded and verified file: /root/.medmnist/pneumoniamnist_224.npz\nUsing downloaded and verified file: /root/.medmnist/pneumoniamnist_224.npz\n\n[1.93904448 0.67372639]\n\n","output_type":"stream"},{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n100%|| 528M/528M [00:02<00:00, 223MB/s] \nDownloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n100%|| 44.7M/44.7M [00:00<00:00, 186MB/s]\nDownloading: \"https://download.pytorch.org/models/mobilenet_v3_large-8738ca79.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v3_large-8738ca79.pth\n100%|| 21.1M/21.1M [00:00<00:00, 148MB/s]\nDownloading: \"https://download.pytorch.org/models/swin_t-704ceda3.pth\" to /root/.cache/torch/hub/checkpoints/swin_t-704ceda3.pth\n100%|| 108M/108M [00:00<00:00, 202MB/s] \n","output_type":"stream"},{"name":"stdout","text":"184103205 184103205 \n\n\nEpoch 1/50 \n------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 1/50:   0%|          | 0/148 [00:00<?, ?batch/s]/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\nTraining Epoch 1/50:  99%|| 147/148 [00:42<00:00,  3.49batch/s, loss=0.70865, acc=0.80777, lr=[0.001]]/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\nTraining Epoch 1/50: 100%|| 148/148 [00:42<00:00,  3.46batch/s, loss=0.70865, acc=0.80777, lr=[0.001]]\n","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.37287, acc: 0.80777, npv: 0.58864, ppv: 0.93659, sen: 0.79479, spe: 0.84514, f1: 0.85989\n","output_type":"stream"},{"name":"stderr","text":"Validation Epoch 1/50: 100%|| 17/17 [00:03<00:00,  5.36batch/s, loss=0.16383, acc=0.93511]\n","output_type":"stream"},{"name":"stdout","text":"Val loss: 0.21832, acc: 0.93511, npv: 0.88550, ppv: 0.95165, sen: 0.96144, spe: 0.85926, f1: 0.95652\nNew best epoch 1\n\nEpoch 2/50 \n------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 2/50: 100%|| 148/148 [00:42<00:00,  3.48batch/s, loss=0.43821, acc=0.90909, lr=[0.001]]\n","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.21760, acc: 0.90909, npv: 0.76590, ppv: 0.97461, sen: 0.90097, spe: 0.93245, f1: 0.93635\n","output_type":"stream"},{"name":"stderr","text":"Validation Epoch 2/50: 100%|| 17/17 [00:03<00:00,  5.38batch/s, loss=0.24054, acc=0.93511]\n","output_type":"stream"},{"name":"stdout","text":"Val loss: 0.23592, acc: 0.93511, npv: 0.92437, ppv: 0.93827, sen: 0.97686, spe: 0.81481, f1: 0.95718\n\nEpoch 3/50 \n------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 3/50: 100%|| 148/148 [00:42<00:00,  3.48batch/s, loss=0.03863, acc=0.93522, lr=[0.001]]\n","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.15315, acc: 0.93522, npv: 0.82627, ppv: 0.98100, sen: 0.93074, spe: 0.94811, f1: 0.95521\n","output_type":"stream"},{"name":"stderr","text":"Validation Epoch 3/50: 100%|| 17/17 [00:03<00:00,  5.42batch/s, loss=0.07083, acc=0.96756]\n","output_type":"stream"},{"name":"stdout","text":"Val loss: 0.10866, acc: 0.96756, npv: 0.90972, ppv: 0.98947, sen: 0.96658, spe: 0.97037, f1: 0.97789\nNew best epoch 3\n\nEpoch 4/50 \n------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 4/50: 100%|| 148/148 [00:42<00:00,  3.49batch/s, loss=0.02598, acc=0.94414, lr=[0.001]]\n","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.13340, acc: 0.94414, npv: 0.84835, ppv: 0.98325, sen: 0.94076, spe: 0.95387, f1: 0.96153\n","output_type":"stream"},{"name":"stderr","text":"Validation Epoch 4/50: 100%|| 17/17 [00:03<00:00,  5.40batch/s, loss=0.12614, acc=0.96947]\n","output_type":"stream"},{"name":"stdout","text":"Val loss: 0.12584, acc: 0.96947, npv: 0.92806, ppv: 0.98442, sen: 0.97429, spe: 0.95556, f1: 0.97933\n\nEpoch 5/50 \n------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 5/50: 100%|| 148/148 [00:42<00:00,  3.48batch/s, loss=0.00029, acc=0.96028, lr=[0.001]]\n","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.10184, acc: 0.96028, npv: 0.88638, ppv: 0.98935, sen: 0.95678, spe: 0.97035, f1: 0.97279\n","output_type":"stream"},{"name":"stderr","text":"Validation Epoch 5/50: 100%|| 17/17 [00:03<00:00,  5.40batch/s, loss=0.13275, acc=0.97519]\n","output_type":"stream"},{"name":"stdout","text":"Val loss: 0.10320, acc: 0.97519, npv: 0.94203, ppv: 0.98705, sen: 0.97943, spe: 0.96296, f1: 0.98323\nNew best epoch 5\n\nEpoch 6/50 \n------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 6/50: 100%|| 148/148 [00:42<00:00,  3.48batch/s, loss=0.00594, acc=0.95816, lr=[0.001]]\n","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.10339, acc: 0.95816, npv: 0.87919, ppv: 0.98960, sen: 0.95363, spe: 0.97117, f1: 0.97129\n","output_type":"stream"},{"name":"stderr","text":"Validation Epoch 6/50: 100%|| 17/17 [00:03<00:00,  5.41batch/s, loss=0.05451, acc=0.96374]\n","output_type":"stream"},{"name":"stdout","text":"Val loss: 0.08057, acc: 0.96374, npv: 0.90278, ppv: 0.98684, sen: 0.96401, spe: 0.96296, f1: 0.97529\nNew best epoch 6\n\nEpoch 7/50 \n------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 7/50: 100%|| 148/148 [00:42<00:00,  3.48batch/s, loss=0.01904, acc=0.96580, lr=[0.001]]\n","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.08055, acc: 0.96580, npv: 0.90099, ppv: 0.99087, sen: 0.96279, spe: 0.97446, f1: 0.97663\n","output_type":"stream"},{"name":"stderr","text":"Validation Epoch 7/50: 100%|| 17/17 [00:03<00:00,  5.41batch/s, loss=0.06807, acc=0.96374]\n","output_type":"stream"},{"name":"stdout","text":"Val loss: 0.07607, acc: 0.96374, npv: 0.88158, ppv: 0.99731, sen: 0.95373, spe: 0.99259, f1: 0.97503\nNew best epoch 7\n\nEpoch 8/50 \n------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 8/50: 100%|| 148/148 [00:42<00:00,  3.49batch/s, loss=0.04361, acc=0.97175, lr=[0.001]]\n","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.07501, acc: 0.97175, npv: 0.91867, ppv: 0.99181, sen: 0.96995, spe: 0.97694, f1: 0.98076\n","output_type":"stream"},{"name":"stderr","text":"Validation Epoch 8/50: 100%|| 17/17 [00:03<00:00,  5.41batch/s, loss=0.04438, acc=0.97519]\n","output_type":"stream"},{"name":"stdout","text":"Val loss: 0.08139, acc: 0.97519, npv: 0.94853, ppv: 0.98454, sen: 0.98201, spe: 0.95556, f1: 0.98327\n\nEpoch 9/50 \n------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 9/50: 100%|| 148/148 [00:42<00:00,  3.48batch/s, loss=0.00744, acc=0.97175, lr=[0.001]]\n","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.06931, acc: 0.97175, npv: 0.91545, ppv: 0.99325, sen: 0.96852, spe: 0.98105, f1: 0.98073\n","output_type":"stream"},{"name":"stderr","text":"Validation Epoch 9/50: 100%|| 17/17 [00:03<00:00,  5.41batch/s, loss=0.02224, acc=0.97901]\n","output_type":"stream"},{"name":"stdout","text":"Val loss: 0.07162, acc: 0.97901, npv: 0.95588, ppv: 0.98711, sen: 0.98458, spe: 0.96296, f1: 0.98584\nNew best epoch 9\n\nEpoch 10/50 \n------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 10/50: 100%|| 148/148 [00:42<00:00,  3.48batch/s, loss=0.00321, acc=0.96984, lr=[0.001]]\n","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.08032, acc: 0.96984, npv: 0.91745, ppv: 0.98949, sen: 0.96966, spe: 0.97035, f1: 0.97947\n","output_type":"stream"},{"name":"stderr","text":"Validation Epoch 10/50: 100%|| 17/17 [00:03<00:00,  5.37batch/s, loss=0.09160, acc=0.95229]\n","output_type":"stream"},{"name":"stdout","text":"Val loss: 0.09236, acc: 0.95229, npv: 0.85256, ppv: 0.99457, sen: 0.94087, spe: 0.98519, f1: 0.96697\n\nEpoch 11/50 \n------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 11/50: 100%|| 148/148 [00:42<00:00,  3.48batch/s, loss=0.91765, acc=0.96856, lr=[0.001]]\n","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.07752, acc: 0.96856, npv: 0.90563, ppv: 0.99293, sen: 0.96451, spe: 0.98023, f1: 0.97851\n","output_type":"stream"},{"name":"stderr","text":"Validation Epoch 11/50: 100%|| 17/17 [00:03<00:00,  5.41batch/s, loss=0.02913, acc=0.96565]\n","output_type":"stream"},{"name":"stdout","text":"Val loss: 0.06482, acc: 0.96565, npv: 0.88742, ppv: 0.99732, sen: 0.95630, spe: 0.99259, f1: 0.97638\nNew best epoch 11\n\nEpoch 12/50 \n------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 12/50: 100%|| 148/148 [00:42<00:00,  3.48batch/s, loss=0.35394, acc=0.96495, lr=[0.001]]\n","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.08868, acc: 0.96495, npv: 0.90130, ppv: 0.98941, sen: 0.96308, spe: 0.97035, f1: 0.97607\n","output_type":"stream"},{"name":"stderr","text":"Validation Epoch 12/50: 100%|| 17/17 [00:03<00:00,  5.45batch/s, loss=0.14197, acc=0.97137]\n","output_type":"stream"},{"name":"stdout","text":"Val loss: 0.12646, acc: 0.97137, npv: 0.97619, ppv: 0.96985, sen: 0.99229, spe: 0.91111, f1: 0.98094\n\nEpoch 13/50 \n------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 13/50: 100%|| 148/148 [00:42<00:00,  3.48batch/s, loss=0.01205, acc=0.97154, lr=[0.001]]\n","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.07239, acc: 0.97154, npv: 0.91475, ppv: 0.99325, sen: 0.96823, spe: 0.98105, f1: 0.98058\n","output_type":"stream"},{"name":"stderr","text":"Validation Epoch 13/50: 100%|| 17/17 [00:03<00:00,  5.35batch/s, loss=0.03616, acc=0.98473]\n","output_type":"stream"},{"name":"stdout","text":"Val loss: 0.06320, acc: 0.98473, npv: 0.96350, ppv: 0.99225, sen: 0.98715, spe: 0.97778, f1: 0.98969\nNew best epoch 13\n\nEpoch 14/50 \n------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 14/50: 100%|| 148/148 [00:42<00:00,  3.48batch/s, loss=0.00112, acc=0.97940, lr=[0.001]]\n","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.05477, acc: 0.97940, npv: 0.93667, ppv: 0.99533, sen: 0.97682, spe: 0.98682, f1: 0.98599\n","output_type":"stream"},{"name":"stderr","text":"Validation Epoch 14/50: 100%|| 17/17 [00:03<00:00,  5.39batch/s, loss=0.04224, acc=0.97328]\n","output_type":"stream"},{"name":"stdout","text":"Val loss: 0.06865, acc: 0.97328, npv: 0.91156, ppv: 0.99735, sen: 0.96658, spe: 0.99259, f1: 0.98172\n\nEpoch 15/50 \n------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 15/50: 100%|| 148/148 [00:42<00:00,  3.48batch/s, loss=0.00005, acc=0.98003, lr=[0.001]]\n","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.04917, acc: 0.98003, npv: 0.93818, ppv: 0.99563, sen: 0.97739, spe: 0.98764, f1: 0.98642\n","output_type":"stream"},{"name":"stderr","text":"Validation Epoch 15/50: 100%|| 17/17 [00:03<00:00,  5.32batch/s, loss=0.01952, acc=0.97710]\n","output_type":"stream"},{"name":"stdout","text":"Val loss: 0.05048, acc: 0.97710, npv: 0.93007, ppv: 0.99475, sen: 0.97429, spe: 0.98519, f1: 0.98442\nNew best epoch 15\n\nEpoch 16/50 \n------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 16/50: 100%|| 148/148 [00:42<00:00,  3.48batch/s, loss=0.00455, acc=0.97621, lr=[0.001]]\n","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.06170, acc: 0.97621, npv: 0.93047, ppv: 0.99329, sen: 0.97453, spe: 0.98105, f1: 0.98382\n","output_type":"stream"},{"name":"stderr","text":"Validation Epoch 16/50: 100%|| 17/17 [00:03<00:00,  5.42batch/s, loss=0.11119, acc=0.96947]\n","output_type":"stream"},{"name":"stdout","text":"Val loss: 0.05766, acc: 0.96947, npv: 0.89933, ppv: 0.99733, sen: 0.96144, spe: 0.99259, f1: 0.97906\n\nEpoch 17/50 \n------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 17/50: 100%|| 148/148 [00:42<00:00,  3.48batch/s, loss=1.62414, acc=0.98067, lr=[0.001]]\n","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.04967, acc: 0.98067, npv: 0.94458, ppv: 0.99390, sen: 0.97997, spe: 0.98270, f1: 0.98689\n","output_type":"stream"},{"name":"stderr","text":"Validation Epoch 17/50: 100%|| 17/17 [00:03<00:00,  5.36batch/s, loss=0.03465, acc=0.97137]\n","output_type":"stream"},{"name":"stdout","text":"Val loss: 0.11341, acc: 0.97137, npv: 0.98387, ppv: 0.96750, sen: 0.99486, spe: 0.90370, f1: 0.98099\n\nEpoch 18/50 \n------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 18/50: 100%|| 148/148 [00:42<00:00,  3.48batch/s, loss=0.08658, acc=0.97366, lr=[0.001]]\n","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.06334, acc: 0.97366, npv: 0.92248, ppv: 0.99298, sen: 0.97138, spe: 0.98023, f1: 0.98206\n","output_type":"stream"},{"name":"stderr","text":"Validation Epoch 18/50: 100%|| 17/17 [00:03<00:00,  5.39batch/s, loss=0.01159, acc=0.98282]\n","output_type":"stream"},{"name":"stdout","text":"Val loss: 0.05865, acc: 0.98282, npv: 0.95000, ppv: 0.99479, sen: 0.98201, spe: 0.98519, f1: 0.98836\n\nEpoch 19/50 \n------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 19/50: 100%|| 148/148 [00:42<00:00,  3.48batch/s, loss=0.00024, acc=0.98471, lr=[0.001]]\n","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.04035, acc: 0.98471, npv: 0.95317, ppv: 0.99623, sen: 0.98311, spe: 0.98929, f1: 0.98963\n","output_type":"stream"},{"name":"stderr","text":"Validation Epoch 19/50: 100%|| 17/17 [00:03<00:00,  5.37batch/s, loss=0.01340, acc=0.98282]\n","output_type":"stream"},{"name":"stdout","text":"Val loss: 0.05161, acc: 0.98282, npv: 0.95000, ppv: 0.99479, sen: 0.98201, spe: 0.98519, f1: 0.98836\n\nEpoch 20/50 \n------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 20/50: 100%|| 148/148 [00:42<00:00,  3.48batch/s, loss=0.00032, acc=0.98237, lr=[0.001]]\n","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.04145, acc: 0.98237, npv: 0.94423, ppv: 0.99651, sen: 0.97968, spe: 0.99012, f1: 0.98802\n","output_type":"stream"},{"name":"stderr","text":"Validation Epoch 20/50: 100%|| 17/17 [00:03<00:00,  5.34batch/s, loss=0.00382, acc=0.97710]\n","output_type":"stream"},{"name":"stdout","text":"Val loss: 0.07603, acc: 0.97710, npv: 0.94245, ppv: 0.98961, sen: 0.97943, spe: 0.97037, f1: 0.98450\n\nEpoch 21/50 \n------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 21/50: 100%|| 148/148 [00:42<00:00,  3.48batch/s, loss=0.00029, acc=0.98407, lr=[0.001]]\n","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.03632, acc: 0.98407, npv: 0.95020, ppv: 0.99651, sen: 0.98197, spe: 0.99012, f1: 0.98919\n","output_type":"stream"},{"name":"stderr","text":"Validation Epoch 21/50: 100%|| 17/17 [00:03<00:00,  5.32batch/s, loss=0.00437, acc=0.98664]\n","output_type":"stream"},{"name":"stdout","text":"Val loss: 0.06537, acc: 0.98664, npv: 0.97059, ppv: 0.99227, sen: 0.98972, spe: 0.97778, f1: 0.99099\n\nEpoch 22/50 \n------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 22/50: 100%|| 148/148 [00:42<00:00,  3.48batch/s, loss=0.02706, acc=0.98513, lr=[0.0005]]\n","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.03409, acc: 0.98513, npv: 0.95907, ppv: 0.99451, sen: 0.98540, spe: 0.98435, f1: 0.98994\n","output_type":"stream"},{"name":"stderr","text":"Validation Epoch 22/50: 100%|| 17/17 [00:03<00:00,  5.40batch/s, loss=0.00854, acc=0.98282]\n","output_type":"stream"},{"name":"stdout","text":"Val loss: 0.05119, acc: 0.98282, npv: 0.95652, ppv: 0.99223, sen: 0.98458, spe: 0.97778, f1: 0.98839\n\nEpoch 23/50 \n------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 23/50: 100%|| 148/148 [00:42<00:00,  3.48batch/s, loss=0.00194, acc=0.98874, lr=[0.0005]]\n","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.02935, acc: 0.98874, npv: 0.96552, ppv: 0.99711, sen: 0.98769, spe: 0.99176, f1: 0.99238\n","output_type":"stream"},{"name":"stderr","text":"Validation Epoch 23/50: 100%|| 17/17 [00:03<00:00,  5.36batch/s, loss=0.03553, acc=0.97137]\n","output_type":"stream"},{"name":"stdout","text":"Val loss: 0.06953, acc: 0.97137, npv: 0.90541, ppv: 0.99734, sen: 0.96401, spe: 0.99259, f1: 0.98039\n\nEpoch 24/50 \n------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 24/50: 100%|| 148/148 [00:42<00:00,  3.47batch/s, loss=0.00001, acc=0.98874, lr=[0.0005]]\n","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.03207, acc: 0.98874, npv: 0.96477, ppv: 0.99740, sen: 0.98741, spe: 0.99259, f1: 0.99238\n","output_type":"stream"},{"name":"stderr","text":"Validation Epoch 24/50: 100%|| 17/17 [00:03<00:00,  5.41batch/s, loss=0.01494, acc=0.97901]\n","output_type":"stream"},{"name":"stdout","text":"Val loss: 0.06958, acc: 0.97901, npv: 0.94928, ppv: 0.98964, sen: 0.98201, spe: 0.97037, f1: 0.98581\n\nEpoch 25/50 \n------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 25/50: 100%|| 148/148 [00:42<00:00,  3.48batch/s, loss=0.07604, acc=0.98152, lr=[0.0005]]\n","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.04829, acc: 0.98152, npv: 0.94687, ppv: 0.99420, sen: 0.98082, spe: 0.98353, f1: 0.98747\n","output_type":"stream"},{"name":"stderr","text":"Validation Epoch 25/50: 100%|| 17/17 [00:03<00:00,  5.38batch/s, loss=0.01940, acc=0.98092]\n","output_type":"stream"},{"name":"stdout","text":"Val loss: 0.10076, acc: 0.98092, npv: 0.97710, ppv: 0.98219, sen: 0.99229, spe: 0.94815, f1: 0.98721\nEarly stopping at epoch 25\nModel saved at /kaggle/working/early_stop_model_epoch_25.pth\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[14], line 393\u001b[0m\n\u001b[1;32m    390\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    391\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining only. Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.5f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt_acc\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.5f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 393\u001b[0m model_save_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(kaggle_working_directory, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFinal_model_epoch_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43msepoch\u001b[49m\u001b[38;5;241m+\u001b[39mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    394\u001b[0m optimizer_save_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(kaggle_working_directory, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFinal_optimizer_epoch_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msepoch\u001b[38;5;241m+\u001b[39mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    395\u001b[0m \u001b[38;5;66;03m#             if epoch > 15:\u001b[39;00m\n","\u001b[0;31mNameError\u001b[0m: name 'sepoch' is not defined"],"ename":"NameError","evalue":"name 'sepoch' is not defined","output_type":"error"}]},{"cell_type":"markdown","source":"## tst","metadata":{}},{"cell_type":"code","source":"import time\nimport torch\nfrom torch.utils.data import DataLoader\nfrom tqdm import tqdm\nimport os\nfrom sklearn.metrics import roc_curve, auc, confusion_matrix, ConfusionMatrixDisplay\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom torch.nn import functional as F\n\n# Evaluation function to calculate accuracy, npv, ppv, etc.\ndef evaluation(true_labels, pred_labels):\n    true_labels = torch.cat(true_labels).cpu().numpy()\n    pred_labels = torch.cat(pred_labels).cpu().numpy()\n\n    tp = ((pred_labels == 1) & (true_labels == 1)).sum()\n    tn = ((pred_labels == 0) & (true_labels == 0)).sum()\n    fp = ((pred_labels == 1) & (true_labels == 0)).sum()\n    fn = ((pred_labels == 0) & (true_labels == 1)).sum()\n\n    accuracy = (tp + tn) / (tp + tn + fp + fn)\n    npv = tn / (tn + fn) if (tn + fn) > 0 else 0.0\n    ppv = tp / (tp + fp) if (tp + fp) > 0 else 0.0  # Precision\n    sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0.0  # Recall\n    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0.0  # True negative rate\n    fpr = fp / (fp + tn) if (fp + tn) > 0 else 0.0  # False positive rate\n    f1_score = 2 * ppv * sensitivity / (ppv + sensitivity) if (ppv + sensitivity) > 0 else 0.0\n\n    return accuracy, npv, ppv, sensitivity, specificity, f1_score, fpr\n\n# Define the test function\ndef test(model_name, model_class, test_loader, log_directory, bp=False):\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n    # Set loss function (using CrossEntropyLoss)\n    loss_func = torch.nn.CrossEntropyLoss()\n\n    # Load the model and push to device\n    model = model_class().to(device)\n    model_path = os.path.join(log_directory, model_name)\n    model_dict = torch.load(model_path, map_location=device)\n    model.load_state_dict(model_dict)\n\n    # Initialize tracking variables\n    te_loss, te_loss_b, te_in = 0, 0, 0\n    te_tle, te_ple = [], []\n    all_probs = []\n\n    print('Model testing started')\n    since = time.time()\n    model.eval()\n\n    for step, (t_x, t_y) in enumerate(tqdm(test_loader, desc=\"Testing\", unit=\"batch\")):\n        t_x, t_y = t_x.to(device), t_y.to(device).squeeze(1)\n        te_tle.append(t_y)\n        output = model(t_x)\n\n        # Compute loss and probabilities\n        loss = loss_func(output, t_y.long())\n        probs = torch.softmax(output, dim=1)[:, 1]  # Probability of the positive class\n        all_probs.append(probs.detach().cpu().numpy())  # Detach and convert to numpy\n\n        # Determine the predicted labels\n        lab = torch.argmax(output, dim=1)\n        te_ple.append(lab)\n        te_loss_b += loss.item() * t_x.size(0)\n        te_in += t_x.size(0)\n\n    # Final calculations\n    t_c = time.time() - since\n    te_loss = te_loss_b / len(test_loader.dataset)\n    te_acc, te_npv, te_ppv, te_sen, te_spe, te_fos, te_fpr = evaluation(te_tle, te_ple)\n\n    # Flatten the list of probabilities and true labels for ROC and confusion matrix\n    all_probs = np.concatenate(all_probs)\n    true_labels = torch.cat(te_tle).cpu().numpy()\n\n    # Compute ROC curve and AUC\n    fpr, tpr, thresholds = roc_curve(true_labels, all_probs)\n    roc_auc = auc(fpr, tpr)\n\n    # Plot ROC curve and save\n    plt.figure()\n    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.4f})')\n    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('Receiver Operating Characteristic')\n    plt.legend(loc=\"lower right\")\n    plt.savefig(\"/kaggle/working/roc_curve.png\")\n    plt.show()\n\n    # Compute confusion matrix\n    pred_labels = torch.cat(te_ple).cpu().numpy()\n    cm = confusion_matrix(true_labels, pred_labels)\n    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n    disp.plot(cmap='Blues')\n    plt.title(f'Confusion Matrix - {model_name}')\n    plt.savefig(\"/kaggle/working/confusion_matrix.png\")\n    plt.show()\n\n    # Print summary metrics\n    print(f'Test done in {t_c // 60} m {t_c % 60} s \\nTest loss: {te_loss:.5f}, acc: {te_acc:.5f}, '\n          f'npv: {te_npv:.5f}, ppv: {te_ppv:.5f}, sen: {te_sen:.5f}, spe: {te_spe:.5f}, fos: {te_fos:.5f}, fpr: {te_fpr:.5f}')\n\n# Example usage:\nlog_directory = \"/kaggle/working\"\nmodel_name = \"early_stop_model_epoch_25.pth\"  # Set your model name here\nmodel_class = CECT  # Define your model class here\ntest_batch_size = 32\n\n# Define your test DataLoader here\ntest_loader = DataLoader(test_dataset, batch_size=test_batch_size, shuffle=False, num_workers=os.cpu_count())\n\n# Run the test function\ntest(model_name, model_class, test_loader, log_directory, bp=False)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-20T17:24:20.987632Z","iopub.execute_input":"2024-09-20T17:24:20.988375Z","iopub.status.idle":"2024-09-20T17:24:29.139892Z","shell.execute_reply.started":"2024-09-20T17:24:20.988335Z","shell.execute_reply":"2024-09-20T17:24:29.138797Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_37/2415919444.py:41: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model_dict = torch.load(model_path, map_location=device)\n","output_type":"stream"},{"name":"stdout","text":"Model testing started\n","output_type":"stream"},{"name":"stderr","text":"Testing: 100%|| 20/20 [00:03<00:00,  5.43batch/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAkIAAAHHCAYAAABTMjf2AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAB6zUlEQVR4nO3dd1QU198G8GdZekcRQUQp9q5YsWCLGBMVNYpREY0au7Elwa5J1NhLYk8UNfqzRI1EDSQau8SCYheiiB0URZoU2b3vH75MsqHIIjDAPp9zOMneuTP77A7rfrlzZ0YhhBAgIiIi0kF6cgcgIiIikgsLISIiItJZLISIiIhIZ7EQIiIiIp3FQoiIiIh0FgshIiIi0lkshIiIiEhnsRAiIiIincVCiIiIiHQWCyGiAuLs7IxBgwbJHUPntG3bFm3btpU7xlvNnj0bCoUCsbGxckcpdhQKBWbPnl0g24qKioJCoUBAQECBbI9KPxZCVCIEBARAoVBIP/r6+nB0dMSgQYPw6NEjueMVa8nJyfj6669Rr149mJqawsrKCq1bt8aWLVtQUu6wc+PGDcyePRtRUVFyR8lCpVJh06ZNaNu2LcqUKQMjIyM4Oztj8ODBuHDhgtzxCsT27duxfPlyuWNoKI6ZqGTSlzsAkTa++uoruLi4IDU1FX/99RcCAgJw6tQpXLt2DcbGxrJmCw8Ph55e8frbIiYmBh06dMDNmzfRt29fjBkzBqmpqdizZw/8/Pxw6NAhbNu2DUqlUu6oubpx4wbmzJmDtm3bwtnZWWPZ77//Lk8oACkpKejZsyeCgoLQpk0bTJ06FWXKlEFUVBR27dqFzZs34/79+6hYsaJsGQvC9u3bce3aNYwfP75Qtp+SkgJ9fe2+jnLKVLlyZaSkpMDAwKAAE1JpxkKISpT3338fjRs3BgAMHToUtra2WLBgAQIDA9GnTx9ZsxkZGRX5c6ampsLQ0DDHAszPzw83b97Evn370K1bN6l93Lhx+Pzzz7F48WI0bNgQX375ZVFFBvBmlMrMzKxAtmVoaFgg28mPzz//HEFBQVi2bFmWL+RZs2Zh2bJlRZpHCIHU1FSYmJgU6fPmh1qtRnp6OoyNjQv0jxiFQiH7H0VUwgiiEmDTpk0CgDh//rxG+4EDBwQAMW/ePI32mzdvil69egkbGxthZGQk3N3dxf79+7NsNy4uTowfP15UrlxZGBoaCkdHR+Hr6yuePXsm9UlNTRUzZ84Ubm5uwtDQUFSsWFF8/vnnIjU1VWNblStXFn5+fkIIIc6fPy8AiICAgCzPGRQUJACIX3/9VWp7+PChGDx4sLCzsxOGhoaiVq1a4scff9RY7+jRowKA+N///iemTZsmKlSoIBQKhYiLi8v2PQsJCREAxCeffJLt8tevX4uqVasKGxsb8erVKyGEEHfv3hUAxKJFi8TSpUtFpUqVhLGxsWjTpo24evVqlm3k5X3O3HfHjh0TI0eOFOXKlRPW1tZCCCGioqLEyJEjRbVq1YSxsbEoU6aM+Oijj8Tdu3ezrP/fn6NHjwohhPD09BSenp5Z3qedO3eKb775Rjg6OgojIyPRvn178ffff2d5Dd9//71wcXERxsbGokmTJuLEiRNZtpmdBw8eCH19ffHee+/l2i/TrFmzBADx999/Cz8/P2FlZSUsLS3FoEGDRHJyskbfjRs3inbt2oly5coJQ0NDUbNmTbF69eos26xcubL44IMPRFBQkHB3dxdGRkZi2bJlWm1DCCEOHTok2rRpI8zNzYWFhYVo3Lix2LZtmxDizfv73/e+cuXK0rp5/XwAEKNHjxY//fSTqFWrltDX1xf79u2Tls2aNUvqm5CQID777DPpc1muXDnRsWNHERoa+tZMmb/DmzZt0nj+mzdvit69ewtbW1thbGwsqlWrJqZOnZrbLiMdwREhKtEy54zY2NhIbdevX0fLli3h6OgIf39/mJmZYdeuXfD29saePXvQo0cPAEBSUhJat26Nmzdv4pNPPkGjRo0QGxuLwMBAPHz4ELa2tlCr1ejWrRtOnTqFTz/9FDVr1sTVq1exbNkyRERE4Jdffsk2V+PGjeHq6opdu3bBz89PY9nOnTthY2MDLy8vAG8OXzVv3hwKhQJjxoxBuXLl8Ntvv2HIkCFISEjIMtLw9ddfw9DQEJMnT0ZaWlqOIyK//vorAGDgwIHZLtfX10e/fv0wZ84cnD59Gh07dpSWbdmyBYmJiRg9ejRSU1OxYsUKtG/fHlevXkX58uW1ep8zjRo1CuXKlcPMmTORnJwMADh//jzOnDmDvn37omLFioiKisKaNWvQtm1b3LhxA6ampmjTpg3GjRuHlStXYurUqahZsyYASP/Nybfffgs9PT1MnjwZ8fHxWLhwIfr374+zZ89KfdasWYMxY8agdevWmDBhAqKiouDt7Q0bG5u3Hs767bffkJGRAV9f31z7/VefPn3g4uKC+fPn4+LFi/jhhx9gZ2eHBQsWaOSqXbs2unXrBn19ffz6668YNWoU1Go1Ro8erbG98PBwfPzxxxg+fDiGDRuG6tWra7WNgIAAfPLJJ6hduzamTJkCa2trXLp0CUFBQejXrx+mTZuG+Ph4PHz4UBrhMjc3BwCtPx9//vkndu3ahTFjxsDW1jbLYc5MI0aMwM8//4wxY8agVq1aeP78OU6dOoWbN2+iUaNGuWbKzpUrV9C6dWsYGBjg008/hbOzM+7cuYNff/0Vc+fOzduOo9JL7kqMKC8yRwUOHz4snj17Jh48eCB+/vlnUa5cOWFkZCQePHgg9e3QoYOoW7euxl+karVaeHh4iKpVq0ptM2fOFADE3r17szyfWq0WQgixdetWoaenJ06ePKmxfO3atQKAOH36tNT27xEhIYSYMmWKMDAwEC9evJDa0tLShLW1tcYozZAhQ4SDg4OIjY3VeI6+ffsKKysrabQmc6TD1dVVasuNt7e3AJDjiJEQQuzdu1cAECtXrhRC/PPXtImJiXj48KHU7+zZswKAmDBhgtSW1/c5c9+1atVKZGRkaDx/dq8jcyRry5YtUtvu3bs1RoH+LacRoZo1a4q0tDSpfcWKFQKANLKVlpYmypYtK5o0aSJev34t9QsICBAA3joiNGHCBAFAXLp0Kdd+mTJHhP47QtejRw9RtmxZjbbs3hcvLy/h6uqq0Va5cmUBQAQFBWXpn5dtvHz5UlhYWIhmzZqJlJQUjb6ZnwEhhPjggw80RoEyafP5ACD09PTE9evXs2wH/xkRsrKyEqNHj87S799yypTdiFCbNm2EhYWFuHfvXo6vkXRX8ZrZSfQWHTt2RLly5eDk5ISPPvoIZmZmCAwMlP56f/HiBf7880/06dMHiYmJiI2NRWxsLJ4/fw4vLy/8/fff0llme/bsQf369bOMXABv5hkAwO7du1GzZk3UqFFD2lZsbCzat28PADh69GiOWX18fPD69Wvs3btXavv999/x8uVL+Pj4AHgzp2PPnj3o2rUrhBAaz+Hl5YX4+HhcvHhRY7t+fn55mgOSmJgIALCwsMixT+ayhIQEjXZvb284OjpKj5s2bYpmzZrh0KFDALR7nzMNGzYsy6Tsf7+O169f4/nz56hSpQqsra2zvG5tDR48WGO0rHXr1gCAyMhIAMCFCxfw/PlzDBs2TGOibv/+/TVGGHOS+Z7l9v5mZ8SIERqPW7dujefPn2vsg3+/L/Hx8YiNjYWnpyciIyMRHx+vsb6Li4s0uvhvednGH3/8gcTERPj7+2eZV5P5GciNtp8PT09P1KpV663btba2xtmzZ/H48eO39n2bZ8+e4cSJE/jkk09QqVIljWV5eY1U+vHQGJUoq1atQrVq1RAfH4+NGzfixIkTGpOUb9++DSEEZsyYgRkzZmS7jadPn8LR0RF37txBr169cn2+v//+Gzdv3kS5cuVy3FZO6tevjxo1amDnzp0YMmQIgDeHxWxtbaUvimfPnuHly5dYv3491q9fn6fncHFxyTVzpswv6MTERFhbW2fbJ6diqWrVqln6VqtWDbt27QKg3fucW+6UlBTMnz8fmzZtwqNHjzRO5//vF762/vull1ncxMXFAQDu3bsHAKhSpYpGP319/RwP2fybpaUlgH/ew4LIlbnN06dPY9asWQgJCcGrV680+sfHx8PKykp6nNPvQ162cefOHQBAnTp1tHoNmbT9fOT1d3fhwoXw8/ODk5MT3N3d0aVLFwwcOBCurq5aZ8wsfPP7Gqn0YyFEJUrTpk2ls8a8vb3RqlUr9OvXD+Hh4TA3N4darQYATJ48Odu/koGsX3y5UavVqFu3LpYuXZrtcicnp1zX9/Hxwdy5cxEbGwsLCwsEBgbi448/lkYgMvMOGDAgy1yiTPXq1dN4nNczgmrWrIlffvkFV65cQZs2bbLtc+XKFQDI01/p/5af9zm73GPHjsWmTZswfvx4tGjRAlZWVlAoFOjbt6/0HPmV0yUBRAFdO6lGjRoAgKtXr6JBgwZ5Xu9tue7cuYMOHTqgRo0aWLp0KZycnGBoaIhDhw5h2bJlWd6X7N5XbbeRX9p+PvL6u9unTx+0bt0a+/btw++//45FixZhwYIF2Lt3L95///13zk30byyEqMRSKpWYP38+2rVrh++//x7+/v7SX4wGBgYak3+z4+bmhmvXrr21z+XLl9GhQ4d8DaP7+Phgzpw52LNnD8qXL4+EhAT07dtXWl6uXDlYWFhApVK9Na+2PvzwQ8yfPx9btmzJthBSqVTYvn07bGxs0LJlS41lf//9d5b+ERER0kiJNu9zbn7++Wf4+flhyZIlUltqaipevnyp0a8wDmFUrlwZwJvRrXbt2kntGRkZiIqKylKA/tf7778PpVKJn376SesJ07n59ddfkZaWhsDAQI3Ro9wOw+Z3G25ubgCAa9eu5foHQk7v/7t+PnLj4OCAUaNGYdSoUXj69CkaNWqEuXPnSoVQXp8v83f1bZ910l2cI0QlWtu2bdG0aVMsX74cqampsLOzQ9u2bbFu3To8efIkS/9nz55J/9+rVy9cvnwZ+/bty9Iv86/zPn364NGjR9iwYUOWPikpKdLZTzmpWbMm6tati507d2Lnzp1wcHDQKEqUSiV69eqFPXv2ZPsP9b/zasvDwwMdO3bEpk2bcODAgSzLp02bhoiICHzxxRdZ/lL/5ZdfNOb4nDt3DmfPnpW+hLR5n3OjVCqzjNB89913UKlUGm2Z1xz6b4H0Lho3boyyZctiw4YNyMjIkNq3bdsmHT7LjZOTE4YNG4bff/8d3333XZblarUaS5YswcOHD7XKlTli9N/DhJs2bSrwbXTq1AkWFhaYP38+UlNTNZb9e10zM7NsD1W+6+cjOyqVKstz2dnZoUKFCkhLS3trpv8qV64c2rRpg40bN+L+/fsaywpqdJBKNo4IUYn3+eefo3fv3ggICMCIESOwatUqtGrVCnXr1sWwYcPg6uqKmJgYhISE4OHDh7h8+bK03s8//4zevXvjk08+gbu7O168eIHAwECsXbsW9evXh6+vL3bt2oURI0bg6NGjaNmyJVQqFW7duoVdu3YhODhYOlSXEx8fH8ycORPGxsYYMmRIlosffvvttzh69CiaNWuGYcOGoVatWnjx4gUuXryIw4cP48WLF/l+b7Zs2YIOHTqge/fu6NevH1q3bo20tDTs3bsXx44dg4+PDz7//PMs61WpUgWtWrXCyJEjkZaWhuXLl6Ns2bL44osvpD55fZ9z8+GHH2Lr1q2wsrJCrVq1EBISgsOHD6Ns2bIa/Ro0aAClUokFCxYgPj4eRkZGaN++Pezs7PL93hgaGmL27NkYO3Ys2rdvjz59+iAqKgoBAQFwc3PL04jDkiVLcOfOHYwbNw579+7Fhx9+CBsbG9y/fx+7d+/GrVu3NEYA86JTp04wNDRE165dMXz4cCQlJWHDhg2ws7PLtuh8l21YWlpi2bJlGDp0KJo0aYJ+/frBxsYGly9fxqtXr7B582YAgLu7O3bu3ImJEyeiSZMmMDc3R9euXQvk8/FfiYmJqFixIj766CPUr18f5ubmOHz4MM6fP68xcphTpuysXLkSrVq1QqNGjfDpp5/CxcUFUVFROHjwIMLCwrTKR6WQLOeqEWkppwsqCiGESqUSbm5uws3NTTo9+86dO2LgwIHC3t5eGBgYCEdHR/Hhhx+Kn3/+WWPd58+fizFjxghHR0fpYnB+fn4ap7Knp6eLBQsWiNq1awsjIyNhY2Mj3N3dxZw5c0R8fLzU77+nz2f6+++/pYu+nTp1KtvXFxMTI0aPHi2cnJyEgYGBsLe3Fx06dBDr16+X+mSeFr57926t3rvExEQxe/ZsUbt2bWFiYiIsLCxEy5YtRUBAQJbTh/99QcUlS5YIJycnYWRkJFq3bi0uX76cZdt5eZ9z23dxcXFi8ODBwtbWVpibmwsvLy9x69atbN/LDRs2CFdXV6FUKvN0QcX/vk85XWhv5cqVonLlysLIyEg0bdpUnD59Wri7u4vOnTvn4d0VIiMjQ/zwww+idevWwsrKShgYGIjKlSuLwYMHa5xan3n6/L8v1vnv9+ffF5EMDAwU9erVE8bGxsLZ2VksWLBAbNy4MUu/zAsqZiev28js6+HhIUxMTISlpaVo2rSp+N///ictT0pKEv369RPW1tZZLqiY188H/v+CitnBv06fT0tLE59//rmoX7++sLCwEGZmZqJ+/fpZLgaZU6ac9vO1a9dEjx49hLW1tTA2NhbVq1cXM2bMyDYP6RaFEBwbJKI3oqKi4OLigkWLFmHy5Mlyx5GFWq1GuXLl0LNnz2wP+RBR6cI5QkSks1JTU7PME9myZQtevHiBtm3byhOKiIoU5wgRkc7666+/MGHCBPTu3Rtly5bFxYsX8eOPP6JOnTro3bu33PGIqAiwECIineXs7AwnJyesXLkSL168QJkyZTBw4EB8++23st7VnoiKDucIERERkc7iHCEiIiLSWSyEiIiISGfp3BwhtVqNx48fw8LCgnceJiIiKiGEEEhMTESFChWyXJj2XehcIfT48eO33iiTiIiIiqcHDx6gYsWKBbY9nSuELCwsALx5Iy0tLWVOQ0RERHmRkJAAJycn6Xu8oOhcIZR5OMzS0pKFEBERUQlT0NNaOFmaiIiIdBYLISIiItJZLISIiIhIZ7EQIiIiIp3FQoiIiIh0FgshIiIi0lkshIiIiEhnsRAiIiIincVCiIiIiHQWCyEiIiLSWbIWQidOnEDXrl1RoUIFKBQK/PLLL29d59ixY2jUqBGMjIxQpUoVBAQEFHpOIiIiKp1kLYSSk5NRv359rFq1Kk/97969iw8++ADt2rVDWFgYxo8fj6FDhyI4OLiQkxIREVFpJOtNV99//328//77ee6/du1auLi4YMmSJQCAmjVr4tSpU1i2bBm8vLwKKyYRERGVUiXq7vMhISHo2LGjRpuXlxfGjx8vTyAiIir5Ig8CN34CRIbcSSgHajVwPbxwDmKVqEIoOjoa5cuX12grX748EhISkJKSAhMTkyzrpKWlIS0tTXqckJBQ6DlJh8ReB07PAF49lTsJEeVHxivg6SW5U1AuniSYY/BObxy/Y18o2y9RhVB+zJ8/H3PmzJE7RvHyOhkI+gSIuSB3kpIvPlLuBEREpdb+a9UxdHc3xCabAUgtlOcoUYWQvb09YmJiNNpiYmJgaWmZ7WgQAEyZMgUTJ06UHickJMDJyalQcxap9ERAiNz7RJ8HggcDKc/fPM54Vfi5iIhKEj19oNMPQKUOcieh//csNgX9Z+1CcvKbQ5Z25Uzw9FnBP0+JKoRatGiBQ4cOabT98ccfaNGiRY7rGBkZwcjIqLCjFT11BrCrHfDo1Ltvy8T23behy/QMgIZjgCZfyJ2EiPJLoffmh4qNchbA8uXvY9iwX+HtXQNLl3rC1XVWgT+PrIVQUlISbt++LT2+e/cuwsLCUKZMGVSqVAlTpkzBo0ePsGXLFgDAiBEj8P333+OLL77AJ598gj///BO7du3CwYMH5XoJRSvpMRAX8eb/H/+VvyLI3BEwLvPm/x2aAR1WAUrDgstIRESUDyqVGhkZahgZ/VOaDBnSEE5OlujUyQ2JiYmF8ryyFkIXLlxAu3btpMeZh7D8/PwQEBCAJ0+e4P79+9JyFxcXHDx4EBMmTMCKFStQsWJF/PDDD7px6vyTc8D/PAChyn555U65r6+nBGp8DNTyLfhsRERE7+DBg3gMHPgL6tQph+++6yK1KxQKeHlVKdTnVgjxtgkmpUtCQgKsrKwQHx8PS0tLueP849VTIGIPkJGS/fKzc4HUF9kv6/QDUHdI4WUjIiIqJLt2Xcfw4Qfw8uWbydAHD/ZDly5Vs/QrrO/vEjVHqFSKuQRE7AbOzc/7OmVrA25d3/y/TTWgZv/CyUZERFRIEhLSMG7cb9i8+bLU5uRkCQuLop2uwUKoMKUlAKFLgZe3s1+uSn9TBGlDaQj0PgyYFc71FIiIiApbSMgDDBiwD5GRcVKbj09trFnzAWxssj8LvLCwECpM134EQrS8hpFNVaDl3JyXV/BgEURERCVSRoYac+eewNdfn4BK9WZmjoWFIVat6oIBA+pBoVAUeSYWQoUp8UHe+zYYDdQfCdjWLrw8REREMnn+/BW6dv0fQkIeSm0eHk746acecHGxkS0XC6HCola9udZPpg93AeUbZd/XuAxgLN8vARERUWGztjaGvv6bazUplQrMnOmJqVNbS21yYSFUGO4dBg5+DKTE/tNmURGwdpMvExERkYyUSj1s3doDPXvuwqpVXdC8eUW5IwFgIVQ4rv6oWQQBgEk5ebIQERHJ4PjxKJiYGKBpU0eprXJla1y4MEyWuUA54fXEC4M6/Z//r+ABtF0K2BTuBaGIiIiKg/R0FaZMOYx27Tbj44/3IDExTWN5cSqCABZCha/rbsB9gtwpiIiICl14eCxatPgR3357GkIAkZFxWLPmgtyxcsVDY0RERPROhBDYsOEixo8PQkrKmxOFDAz0MHdue0ya5CFzutyxECIiIqJ8e/YsGcOG/Yr9+8OlturVy2L79l5o1MhBxmR5w0KoIMVeA859m7+7whMREZUwwcG3MWjQfkRHJ0ltI0a4Y8kSL5iaGsiYLO9YCBWEyIPA2fnA49NZl+mVjF8EIiIibcTEJMHbeydSU98cCrO1NcXGjd3QtWt1mZNph5OlC8KxidkXQTU+Bkx52jwREZU+5cub49tvOwAAvLzccPXqyBJXBAEcESoYqf/cNA76JkCj8UBTf8DIUrZIREREBUmtFlCp1DAwUEptY8c2Q8WKlujRoyb09IrXafF5xUIoP9QZwLOrANT///j1m/9auQJD78gWi4iIqDA8eZKIQYP2o0GD8liw4D2pXU9PgV69asmY7N2xENKWUANbGwGxV+VOQkREVOj277+FIUMC8fx5Cv744w68vKqgfXsXuWMVGBZC2ngRAVz9IeciyMq1aPMQEREVkuTkdEya9DvWrQuV2sqXN5cxUeFgIZRXydHA5tqad5QHgAaj3/zX0BKoN6zocxERERWw0NDH6NdvLyIinktt3btXxw8/dIOtramMyQoeC6G8enYlaxHU/nug4Wh58hARERUwlUqNxYvPYPr0o8jIeDMP1tTUAMuXe2Ho0EbF7j5hBYGFUH64dgUafQZUaid3EiIiogIRG/sKvXvvxrFjUVKbu7sDtm/vhWrVysoXrJDxOkL5YdcQqNwBUPDtIyKi0sHKyghJSekAAIUCmDKlFc6cGVKqiyCAhRAREREBMDBQYtu2nqhZ0xZHj/ph3rwOMDRUvn3FEo6HxoiIiHRQSMgDmJoaoH59e6mtWrWyuHZtVIm9OGJ+cESIiIhIh2RkqDFnzjG0br0JH3+8B69evdZYrktFEMBCiIiISGdERsahTZtNmD37OFQqgZs3Y7F69Xm5Y8mKh8aIiIhKOSEEtm69gjFjDiEx8c2EaKVSgVmzPDF+fHOZ08mLhVBO1Cog8gDw4tabx3ER8uYhIiLKh7i4FIwYcRC7dl2X2tzcbPDTTz3RvHlFGZMVDyyE/ist4c1tNC4senM1aSIiohLq2LEo+Pruw8OHCVLb4MENsGJFZ1hYGMmYrPhgIfRfocuAkNm596nYpkiiEBER5deTJ4nw8voJ6ekqAICNjTHWrfsQvXvXljlZ8cJC6L/i72Rte38rYPD/N5orUwMoW6NoMxEREWnJwcECs2Z5Ytq0P9GunTO2bOmBihUt5Y5V7LAQyk3X3YDLB4CBidxJiIiIciWEgFotoFT+c0L4l1+2hJOTJfr3r6dzp8XnFU+fz025+iyCiIio2Hv2LBk9euzEN9+c0GhXKvXg61ufRVAuOCJERERUggUH38agQfsRHZ2EAwci0KmTG1q0cJI7VonBQoiIiKgESk3NwJQph7F8+VmpzcbGRLpOEOUNCyEiIqIS5urVGPTvvxdXrz6V2ry83BAQ4A17e3MZk5U8LISIiIhKCLVa4LvvzuLLLw8jLe3NafFGRkosXPgexoxpyrlA+cBCiIiIqAR4/vwV+vffi+Dgfy7zUreuHbZv74U6dexkTFay8awxIiKiEsDMzBCPHiVKjydMaI5z54axCHpHLISIiIhKAGNjfWzf3hMuLtYIDh6ApUu9YGzMAzvviu8gERFRMRQa+hhmZoaoUcNWaqtbtzwiIsZCX5/jGAWF7yQREVExolKpsWDBKTRv/iM+/ngP0tIyNJazCCpYfDeJiIiKiQcP4tGhwxb4+x9BRoYaYWHRWL36vNyxSjUeGiMiIioGdu26juHDD+Dly1QAgEIB+Pu3wujRTWVOVrqxECIiIpJRQkIaxo37DZs3X5banJwssXVrD3h6OssXTEewECIiIpJJSMgDDBiwD5GRcVKbj09trFnzAWxseNPvosBCiIiISAaPHiWgbdvNSE9/c4VoCwtDrFrVBQMG1INCwStEFxVOliYiIpKBo6MlJk9uAQDw8HDC5csj4Otbn0VQEeOIEBERUREQQgCARqEze3ZbVKpkhSFDGvG0eJnwXSciIipkcXEp6Nt3D5YsCdFoNzBQYvjwxiyCZMQRISIiokJ07FgUfH334eHDBOzbdxMdOrigYUMHuWPR/2MJSkREVAjS01Xw9z+M9u034+HDBACAubkhoqOTZE5G/8YRISIiogIWHh6Lfv324uLFJ1Jbu3bO2LKlBypWtJQxGf0XCyEiIqICIoTA+vWhmDAhGCkpb+4RZmCgh7lz22PSJA/o6fGMsOKGhRAREVEBePEiBYMH70dgYLjUVr16WWzf3guNGnFOUHHFQoiIiKgAGBkpcetWrPR45MjGWLy4E0xNDWRMRW/DydJEREQFwMzMENu29USFChYIDOyL1as/YBFUAnBEKNPLO8C5BcCNrXInISKiEuDq1RiYmRnC1dVGamvcuAIiI8fByIhfryUFR4QynZoOXN2g2abHX2QiItKkVgusWPEXmjTZgP799yIjQ62xnEVQycJCKFPyY83Hzl6ApbMsUYiIqHh68iQR77+/DePHByMtTYW//nqINWvOyx2L3oHshdCqVavg7OwMY2NjNGvWDOfOncu1//Lly1G9enWYmJjAyckJEyZMQGpqav4DXNsErLIFHp74p23YfaBXEMAb3xER0f/bv/8W6tZdg99/vyO1TZjQHMOGucuYit6VrON3O3fuxMSJE7F27Vo0a9YMy5cvh5eXF8LDw2FnZ5el//bt2+Hv74+NGzfCw8MDERERGDRoEBQKBZYuXZq/EOcXAqnP/3lsaAGY8zRHIiJ6Izk5HZMm/Y5160KlNgcHcwQEeKNTJzcZk1FBkHVEaOnSpRg2bBgGDx6MWrVqYe3atTA1NcXGjRuz7X/mzBm0bNkS/fr1g7OzMzp16oSPP/74raNIucr4/9EkhRJwaA50WM25QUREBAAIDX2MRo3WaxRB3t41cOXKSBZBpYRshVB6ejpCQ0PRsWPHf8Lo6aFjx44ICQnJdh0PDw+EhoZKhU9kZCQOHTqELl265Pg8aWlpSEhI0PjJlokt0C8EqDUg/y+KiIhKjQcP4uHhsREREW+OGpiaGmDDhq7Yu7cPbG1NZU5HBUW2Qig2NhYqlQrly5fXaC9fvjyio6OzXadfv3746quv0KpVKxgYGMDNzQ1t27bF1KlTc3ye+fPnw8rKSvpxcnIq0NdBRESlk5OTFUaNagwAcHd3wKVLwzF0aCMoOH+0VJF9srQ2jh07hnnz5mH16tW4ePEi9u7di4MHD+Lrr7/OcZ0pU6YgPj5e+nnw4EERJiYiopJECKHxeP78jli6tBPOnBmCatXKypSKCpNsk2FsbW2hVCoRExOj0R4TEwN7e/ts15kxYwZ8fX0xdOhQAEDdunWRnJyMTz/9FNOmTYOeXta6zsjICEZGRgX/AoiIqNRISEjDuHG/oWlTR4wa1URqNzbWx4QJLWRMRoVNthEhQ0NDuLu748iRI1KbWq3GkSNH0KJF9r90r169ylLsKJVKAFmreCIiorwICXmABg3WYvPmy5g06XfcvPlM7khUhGQ9PWrixInw8/ND48aN0bRpUyxfvhzJyckYPHgwAGDgwIFwdHTE/PnzAQBdu3bF0qVL0bBhQzRr1gy3b9/GjBkz0LVrV6kgIiIiyouMDDW++eYEvvnmBFSqN39MGxjo4c6dONSsWU7mdFRUZC2EfHx88OzZM8ycORPR0dFo0KABgoKCpAnU9+/f1xgBmj59OhQKBaZPn45Hjx6hXLly6Nq1K+bOnSvXSyAiohIoMjIOAwbsRUjIQ6nNw8MJP/3UAy4uNrmsSaWNQujYMaWEhARYWVkhPj4elpaWwAYXICEKMC0PjMz+bDUiIiodhBDYsuUyxoz5DUlJ6QAApVKBmTM9MXVqa+jrl6hziHRKlu/vAsIrBxIRkU54+TIVw4cfwK5d16U2V1cbbNvWE82bV5QxGcmJhRAREekEhQI4e/afQ2GDBjXAypWdYWHBM4t1GccAiYhIJ1hZGWPr1h6wtTXFrl0fYdOm7iyCiCNCRERUOoWHx8LMzBAVK/4zn6R168qIivoMZmaGMiaj4oQjQkREVKoIIbBu3QU0bLgOAwfug1qteU4QiyD6NxZCRERUajx7lgxv750YMeIgUlIycPRoFNavD337iqSzeGiMiIhKheDg2xg0aD+io5OkthEj3DFwYH0ZU1Fxx0KIiIhKtNTUDEyZchjLl5+V2mxtTbFxYzd07VpdxmRUErAQIiKiEuvq1Rj0778XV68+ldq8vNwQEOANe3tzGZNRScFCiIiISqR7916iSZMNSEtTAQCMjJRYuPA9jBnTFHp6CpnTUUnBydJERFQiVa5sLc3/qVvXDhcufIpx45qxCCKtcESIiIhKrGXLvFC5shUmTfKAsTG/0kh7HBEiIqJiLzk5HSNGHEBAQJhGu5mZIaZNa8MiiPKNvzlERFSshYY+Rv/+exEe/hzbtl1F69aV4OZWRu5YVEpwRIiIiIollUqNBQtOoXnzHxEe/hwAoFYLXLv29C1rEuUdR4SIiKjYefAgHr6++3D8+D2pzd3dAdu390K1amVlTEalDQshIiIqVnbtuo7hww/g5ctUAIBCAfj7t8Ls2W1haKiUOR2VNiyEiIioWEhMTMPYsb9h8+bLUpuTkyW2bu0BT09n+YJRqcZCiIiIioW0NBV+//2O9NjHpzbWrPkANjYmMqai0o6TpYmIqFiwtTXF5s3esLQ0wpYt3vjf/3qxCKJCxxEhIiKSRWRkHMzMDFC+/D/3BHvvPTfcuzce1tbGMiYjXcIRISIiKlJCCGzeHIb69dfik08CIYTQWM4iiIoSCyEiIioycXEp6Nt3DwYN2o+kpHQcOvQ3Nm0KkzsW6TAeGiMioiJx7FgUfH334eHDBKlt0KAG6N27loypSNexECIiokKVnq7CzJlHsXDhaWQeBbOxMca6dR+id+/a8oYjncdCiIiICs2tW7Ho338vLl58IrW1a+eMLVt6oGJFSxmTEb3BQoiIiApFZGQcGjVah5SUDACAgYEe5s5tj0mTPKCnp5A5HdEbnCxNRESFwtXVBj171gQAVK9eFn/9NRSff96SRRAVKxwRIiKiQrNqVRdUrmyFadPawNTUQO44RFm804hQampqQeUgIqISLDU1AxMmBGH37usa7VZWxpg7twOLICq2tC6E1Go1vv76azg6OsLc3ByRkZEAgBkzZuDHH38s8IBERFS8Xb0ag6ZNN2D58rP49NMDePAgXu5IRHmmdSH0zTffICAgAAsXLoShoaHUXqdOHfzwww8FGo6IiIovtVpgxYq/0KTJBly9+hQAkJLyGhcuPJY5GVHeaV0IbdmyBevXr0f//v2hVCql9vr16+PWrVsFGo6IiIqnJ08S0aXLNowfH4y0NBUAoG5dO1y48Cl69KgpczqivNN6svSjR49QpUqVLO1qtRqvX78ukFBERFR87d9/C0OH/orY2FdS24QJzTFvXgcYG/McHCpZtP6NrVWrFk6ePInKlStrtP/8889o2LBhgQUjIqLiJTk5HZMm/Y5160KlNgcHcwQEeKNTJzcZkxHln9aF0MyZM+Hn54dHjx5BrVZj7969CA8Px5YtW3DgwIHCyEhERMVAQkIa9uy5KT329q6BDRu6wtbWVMZURO9G6zlC3bt3x6+//orDhw/DzMwMM2fOxM2bN/Hrr7/ivffeK4yMRERUDDg4WOCHH7rC1NQAGzZ0xd69fVgEUYmnECLzFni6ISEhAVZWVoiPj4elsQL4wRVIiQVMywMjo+WOR0RUbDx4EA8zM0OUKWOi0f70aTLs7MxkSkW6SuP727Lg7lOn9YiQq6srnj9/nqX95cuXcHV1LZBQRSLxEbCj9ZsiCACMbeTNQ0RUjOzadR316q3F8OEH8N+/l1kEUWmidSEUFRUFlUqVpT0tLQ2PHj0qkFBF4kAf4NnlN/9vZA28t17WOERExUFCQhoGDfoFPj4/4+XLVPz88w1s335V7lhEhSbPk6UDAwOl/w8ODoaVlZX0WKVS4ciRI3B2di7QcIUq9hpgDMDEFvA5CZStIXciIiJZhYQ8QP/+e3H37kupzcenNrp0qSpfKKJCludCyNvbGwCgUCjg5+ensczAwADOzs5YsmRJgYYrElauLIKISKdlZKgxd+4JfP31CahUbw6DWVgYYtWqLhgwoB4UCt4tnkqvPBdCarUaAODi4oLz58/D1ta20EIREVHRiIyMw4ABexES8lBq8/Bwwk8/9YCLC+dOUumn9XWE7t69Wxg5iIioiN2+/QKNGq1DYmI6AECpVGDmTE9Mndoa+vpaTyElKpHydS305ORkHD9+HPfv30d6errGsnHjxhVIMCIiKlxubjbo0MEVv/xyC66uNti2rSeaN68odyyiIqV1IXTp0iV06dIFr169QnJyMsqUKYPY2FiYmprCzs6OhRARUQmhUCiwYUNXVK5sha+/bgcLCyO5IxEVOa3HPidMmICuXbsiLi4OJiYm+Ouvv3Dv3j24u7tj8eLFhZGRiIjeUXq6Cv7+h3HwYIRGu62tKZYv78wiiHSW1oVQWFgYJk2aBD09PSiVSqSlpcHJyQkLFy7E1KlTCyMjERG9g/DwWLRo8SMWLDiNTz4JRExMktyRiIoNrQshAwMD6Om9Wc3Ozg73798HAFhZWeHBgwcFm46IiPJNCIF16y6gYcN1uHjxCQAgLi4Fp0/z32qiTFrPEWrYsCHOnz+PqlWrwtPTEzNnzkRsbCy2bt2KOnXqFEZGIiLS0rNnyRg69FcEBoZLbdWrl8X27b3QqJGDjMmIihetR4TmzZsHB4c3H6K5c+fCxsYGI0eOxLNnz7Bu3boCD0hERNoJDr6NevXWahRBI0c2xsWLw1kEEf2H1iNCjRs3lv7fzs4OQUFBBRqIiIjyJzU1A1OmHMby5WelNltbU2zc2A1du1aXMRlR8VVgV8y6ePEiPvzww4LaHBERaenp02Rs2hQmPe7cuQquXh3JIogoF1oVQsHBwZg8eTKmTp2KyMhIAMCtW7fg7e2NJk2aSLfhICKiolepkhXWrPkARkZKrFzZGYcO9YO9vbncsYiKtTwfGvvxxx8xbNgwlClTBnFxcfjhhx+wdOlSjB07Fj4+Prh27Rpq1qxZmFmJiOhfnjxJhJmZISwt/7kG0Mcf10WrVpXg5GQlYzKikiPPI0IrVqzAggULEBsbi127diE2NharV6/G1atXsXbtWhZBRERFaP/+W6hXby3GjfstyzIWQUR5l+dC6M6dO+jduzcAoGfPntDX18eiRYtQsSLvS0NEVFSSk9MxYsQBeHvvRGzsK2zefBl79tyQOxZRiZXnQ2MpKSkwNTUF8Ob+NEZGRtJp9EREVPhCQx+jX7+9iIh4LrV5e9eAp6ezfKGISjitTp//4YcfYG7+ZuJdRkYGAgICYGtrq9GHN10lIipYKpUaixefwfTpR5GR8eakFFNTA6xY0RlDhjSEQqGQOSFRyaUQQoi8dHR2dn7rh02hUEhnk+XVqlWrsGjRIkRHR6N+/fr47rvv0LRp0xz7v3z5EtOmTcPevXvx4sULVK5cGcuXL0eXLl3y9HwJCQmwsrJC/DeApTEA+6ZA/7NvXY+ISA4PHsTD13cfjh+/J7W5uztg+/ZeqFatrIzJiIqW9P0dHw9LS8sC226eR4SioqIK7Ekz7dy5ExMnTsTatWvRrFkzLF++HF5eXggPD4ednV2W/unp6XjvvfdgZ2eHn3/+GY6Ojrh37x6sra0LPBsRkdwiIp6jWbMf8PJlKgBAoQD8/Vth9uy2MDRUypyOqHTQ+srSBWnp0qUYNmwYBg8eDABYu3YtDh48iI0bN8Lf3z9L/40bN+LFixc4c+YMDAwMALwZqSIiKo2qVCmDZs0cERx8B05Olti6tQfnAxEVsAK7srS20tPTERoaio4dO/4TRk8PHTt2REhISLbrBAYGokWLFhg9ejTKly+POnXqYN68eVCpVEUVm4ioyOjpKbBpU3d8+mkjXL48gkUQUSGQbUQoNjYWKpUK5cuX12gvX748bt26le06kZGR+PPPP9G/f38cOnQIt2/fxqhRo/D69WvMmjUr23XS0tKQlpYmPU5ISCi4F0FEVEAyMtSYO/cEWreujPbtXaR2BwcLrFvXVcZkRKWbrIfGtKVWq2FnZ4f169dDqVTC3d0djx49wqJFi3IshObPn485c+YUcVIioryLjIzDgAF7ERLyEI6OFrhyZSTKlDGROxaRTpDt0JitrS2USiViYmI02mNiYmBvb5/tOg4ODqhWrRqUyn8mCdasWRPR0dFIT0/Pdp0pU6YgPj5e+nnw4EHBvQgioncghMCWLZfRoMFahIQ8BABERyfh6NG7Micj0h35KoTu3LmD6dOn4+OPP8bTp08BAL/99huuX7+e520YGhrC3d0dR44ckdrUajWOHDmCFi1aZLtOy5Ytcfv2bY2bu0ZERMDBwQGGhobZrmNkZARLS0uNHyIiucXFpaBv3z3w8/sFiYlv/pBzdbXBqVOfoFevWjKnI9IdWhdCx48fR926dXH27Fns3bsXSUlJAIDLly/neHgqJxMnTsSGDRuwefNm3Lx5EyNHjkRycrJ0FtnAgQMxZcoUqf/IkSPx4sULfPbZZ4iIiMDBgwcxb948jB49WtuXQUQkm2PHolCv3lrs2vXPH4+DBjVAWNhwNG/O2xYRFSWt5wj5+/vjm2++wcSJE2FhYSG1t2/fHt9//71W2/Lx8cGzZ88wc+ZMREdHo0GDBggKCpImUN+/fx96ev/Uak5OTggODsaECRNQr149ODo64rPPPsOXX36p7csgIipy6ekqzJp1FAsWnEbmpWytrY2xfv2H6N27trzhiHRUnq8sncnc3BxXr16Fi4sLLCwscPnyZbi6uiIqKgo1atRAampqYWUtELyyNBHJJTIyDvXqrUFy8msAQNu2ztiyxZt3iyfKg8K6srTWh8asra3x5MmTLO2XLl2Co6NjgYQiIiqNXF1tsGJFZxgY6GHhwo44cmQgiyAimWl9aKxv37748ssvsXv3bigUCqjVapw+fRqTJ0/GwIEDCyMjEVGJFBv7CqamBjA1NZDaPvmkITw9nVGlShkZkxFRJq1HhObNm4caNWrAyckJSUlJqFWrFtq0aQMPDw9Mnz69MDISEZU4wcG3UbfuGnz++e8a7QqFgkUQUTGi9RyhTPfv38e1a9eQlJSEhg0bomrVqgWdrVBwjhARFabU1AxMmXIYy5f/8+/KgQMf44MPqsmYiqjkk/3u85lOnTqFVq1aoVKlSqhUqVKBBSEiKumuXo1B//57cfXqU6mtc+cqcHevIGMqIsqN1ofG2rdvDxcXF0ydOhU3btwojExERCWKWi2wYsVfaNJkg1QEGRkpsXJlZxw61A/29uYyJySinGhdCD1+/BiTJk3C8ePHUadOHTRo0ACLFi3Cw4cPCyMfEVGx9uRJIrp02Ybx44ORlqYCANSta4cLFz7F2LHNoFAoZE5IRLnRuhCytbXFmDFjcPr0ady5cwe9e/fG5s2b4ezsjPbt2xdGRiKiYik8PBb16q1FcPAdqW3ChOY4d24Y6tSxkzEZEeXVO9101cXFBf7+/vj2229Rt25dHD9+vKByEREVe1WqlEGtWuUAAA4O5ggOHoClS71gbKz19Esikkm+C6HTp09j1KhRcHBwQL9+/VCnTh0cPHiwILMRERVrSqUetm7tAV/ferhyZSQ6dXKTOxIRaUnrP1umTJmCHTt24PHjx3jvvfewYsUKdO/eHaampoWRj4ioWFCp1Fi8+Axat64MDw8nqb1SJSts2dJDxmRE9C60LoROnDiBzz//HH369IGtrW1hZCIiKlYePIiHr+8+HD9+Dy4u1ggLGwFLSyO5YxFRAdC6EDp9+nRh5CAiKpZ27bqO4cMP4OXLNzeUjop6id9/v4OPPqolczIiKgh5KoQCAwPx/vvvw8DAAIGBgbn27datW4EEIyKSU0JCGsaN+w2bN1+W2pycLLF1aw94ejrLF4yIClSeCiFvb29ER0fDzs4O3t7eOfZTKBRQqVQFlY2ISBYhIQ8wYMA+REbGSW0+PrWxZs0HsLExkTEZERW0PBVCarU62/8nIipNMjLUmDv3BL7++gRUqje3YbSwMMSqVV0wYEA9XhyRqBTS+vT5LVu2IC0tLUt7eno6tmzZUiChiIjkcOfOC8yff0oqgjw8nHD58gj4+tZnEURUSmldCA0ePBjx8fFZ2hMTEzF48OACCUVEJIfq1W2xcOF7UCoVmDOnLY4fHwQXFxu5YxFRIdL6rDEhRLZ/GT18+BBWVlYFEoqIqCjExaXA1NQARkb//FM4dmxTtG/vwltkEOmIPBdCDRs2hEKhgEKhQIcOHaCv/8+qKpUKd+/eRefOnQslJBFRQTt2LAq+vvvQt29tLFrUSWpXKBQsgoh0SJ4LocyzxcLCwuDl5QVzc3NpmaGhIZydndGrV68CD0hEVJDS01WYNesoFiw4DSGAxYtD0LlzFXTo4Cp3NCKSQZ4LoVmzZgEAnJ2d4ePjA2Nj40ILRURUGMLDY9Gv315cvPhEamvXzhnVq/Mq+US6Sus5Qn5+foWRg4io0AghsH59KCZMCEZKSgYAwMBAD3PntsekSR7Q0+MZYUS6Kk+FUJkyZRAREQFbW1vY2NjkehrpixcvCiwcEdG7evYsGUOH/orAwHCprXr1sti+vRcaNXKQMRkRFQd5KoSWLVsGCwsL6f95PQ0iKgnCw2PRtu1mREcnSW0jRzbG4sWdYGpqIGMyIiou8lQI/ftw2KBBgworCxFRgXJ1tYGTkyWio5Nga2uKjRu7oWvX6nLHIqJiROsLKl68eBFXr16VHu/fvx/e3t6YOnUq0tPTCzQcEdG7MDBQYtu2nujZsyauXh3JIoiIstC6EBo+fDgiIiIAAJGRkfDx8YGpqSl2796NL774osADEhHlhVotsHLlWVy69ESjvWrVstizpw/s7c1zWJOIdJnWhVBERAQaNGgAANi9ezc8PT2xfft2BAQEYM+ePQWdj4jorZ48SUSXLtvw2WdB6NdvL169ei13JCIqIbQuhIQQ0h3oDx8+jC5dugAAnJycEBsbW7DpiIjeYv/+W6hXby2Cg+8AAG7disVvv/0tcyoiKim0vo5Q48aN8c0336Bjx444fvw41qxZAwC4e/cuypcvX+ABiYiyk5ycjkmTfse6daFSm4ODOQICvNGpk5uMyYioJNG6EFq+fDn69++PX375BdOmTUOVKlUAAD///DM8PDwKPCAR0X+Fhj5Gv357ERHxXGrz9q6BDRu6wtbWVMZkRFTSaF0I1atXT+OssUyLFi2CUqkskFBERNlRqdRYtOgMZsw4ioyMN4foTU0NsHy5F4YObcRrnBGR1rQuhDKFhobi5s2bAIBatWqhUaNGBRaKiCg7t27FahRB7u4O2L69F6pVKytzMiIqqbQuhJ4+fQofHx8cP34c1tbWAICXL1+iXbt22LFjB8qVK1fQGYmIAAC1a9vh66/bYerUI/D3b4XZs9vC0JAj0USUf1qfNTZ27FgkJSXh+vXrePHiBV68eIFr164hISEB48aNK4yMRKSjEhPTpNGfTJ9/7oFz54Zh3rwOLIKI6J1pXQgFBQVh9erVqFmzptRWq1YtrFq1Cr/99luBhiMi3RUS8gANGqzDN9+c0GhXKvXQuHEFmVIRUWmjdSGkVqthYJD1ZoUGBgbS9YWIiPIrI0ONOXOOoXXrTYiMjMPXX5/AmTMP5I5FRKWU1oVQ+/bt8dlnn+Hx48dS26NHjzBhwgR06NChQMMRkW6JjIxDmzabMHv2cahUAgDQvHlFODjw9hhEVDi0LoS+//57JCQkwNnZGW5ubnBzc4OLiwsSEhLw3XffFUZGIirlhBDYsuUyGjRYi5CQhwAApVKBOXPa4vjxQXBxsZE3IBGVWlqfNebk5ISLFy/iyJEj0unzNWvWRMeOHQs8HBGVfnFxKRg58iB27rwutbm62mDbtp5o3ryijMmISBdoVQjt3LkTgYGBSE9PR4cOHTB27NjCykVEOiA8PBbvvbcVDx4kSG2DBjXAypWdYWFhJGMyItIVeS6E1qxZg9GjR6Nq1aowMTHB3r17cefOHSxatKgw8xFRKVa5sjWsrY3x4EECbGyMsW7dh+jdu7bcsYhIh+R5jtD333+PWbNmITw8HGFhYdi8eTNWr15dmNmIqJQzNtbH9u290KVLVVy5MpJFEBEVuTwXQpGRkfDz85Me9+vXDxkZGXjy5EmhBCOi0kUIgfXrQ3HjxjON9jp17HDwYD9UrGgpUzIi0mV5LoTS0tJgZmb2z4p6ejA0NERKSkqhBCOi0uPZs2R4e+/E8OEH0K/fHqSlZcgdiYgIgJaTpWfMmAFTU1PpcXp6OubOnQsrKyupbenSpQWXjohKvODg2xg0aD+io5MAAJcvx+DAgQj06lVL5mRERFoUQm3atEF4eLhGm4eHByIjI6XHCoWi4JIRUYmWmpoBf//DWLHirNRma2uKjRu7oWvX6jImIyL6R54LoWPHjhViDCIqTa5ejUG/fntx7dpTqc3Lyw0BAd6wt+dVoomo+ND6gopERDlRqwW+++4svvzyMNLSVAAAIyMlFi58D2PGNIWeHkeNiah4YSFERAXm6tUYTJz4O9TqN/cJq1vXDtu390KdOnYyJyMiyp7W9xojIspJ/fr2mDq1FQBgwoTmOHduGIsgIirWOCJERPn26tVrGBvraxzymjnTE506uaF168oyJiMiyhuOCBFRvoSGPkbDhuuwZMkZjXYDAyWLICIqMfJVCJ08eRIDBgxAixYt8OjRIwDA1q1bcerUqQINR0TFj0qlxoIFp9C8+Y+IiHiOadP+xMWLvMI8EZVMWhdCe/bsgZeXF0xMTHDp0iWkpaUBAOLj4zFv3rwCD0hExceDB/Ho0GEL/P2PICNDDQCoV688zM0NZU5GRJQ/WhdC33zzDdauXYsNGzbAwMBAam/ZsiUuXrxYoOGIqPjYtes66tVbi+PH7wEAFApgypRWOHNmCKpVKytzOiKi/NF6snR4eDjatGmTpd3KygovX74siExEVIwkJKRh3LjfsHnzZanNyckSW7f2gKens3zBiIgKgNaFkL29PW7fvg1nZ2eN9lOnTsHV1bWgchFRMRAeHosuXbYjMjJOavPxqY21az+EtbWxjMmIiAqG1ofGhg0bhs8++wxnz56FQqHA48ePsW3bNkyePBkjR44sjIxEJJOKFS2hr//mnwkLC0Ns2eKN//2vF4sgIio1tC6E/P390a9fP3To0AFJSUlo06YNhg4diuHDh2Ps2LH5CrFq1So4OzvD2NgYzZo1w7lz5/K03o4dO6BQKODt7Z2v5yWi3JmZGWL79p5o29YZly+PgK9vfd5cmYhKFYUQQuRnxfT0dNy+fRtJSUmoVasWzM3zdyPFnTt3YuDAgVi7di2aNWuG5cuXY/fu3QgPD4edXc5XpI2KikKrVq3g6uqKMmXK4JdffsnT8yUkJMDKygrx3wCWxgDsmwL9z751PaLSTgiBrVuvoGVLJ7i5lcmyjAUQEclJ+v6Oj4elpWWBbTffF1Q0NDRErVq10LRp03wXQQCwdOlSDBs2DIMHD0atWrWwdu1amJqaYuPGjTmuo1Kp0L9/f8yZM4fzkogKQFxcCvr23QM/v1/Qv/9evH6t0ljOIoiISiutJ0u3a9cu138U//zzzzxvKz09HaGhoZgyZYrUpqenh44dOyIkJCTH9b766ivY2dlhyJAhOHnyZK7PkZaWJl3rCHhTURLRP44di4Kv7z48fPjms3H27CMcOBCBHj1qypyMiKjwaV0INWjQQOPx69evERYWhmvXrsHPz0+rbcXGxkKlUqF8+fIa7eXLl8etW7eyXefUqVP48ccfERYWlqfnmD9/PubMmaNVLiJdkJ6uwsyZR7Fw4WlkHiC3sTHG+vVdWQQRkc7QuhBatmxZtu2zZ89GUlLSOwfKTWJiInx9fbFhwwbY2trmaZ0pU6Zg4sSJ0uOEhAQ4OTkVVkSiEiE8PBb9+u3VuDVGu3bO2LKlBypWLLhj70RExV2B3X1+wIABaNq0KRYvXpzndWxtbaFUKhETE6PRHhMTA3t7+yz979y5g6ioKHTt2lVqU6vfXOZfX18f4eHhcHNz01jHyMgIRkZG2rwUolJLCIH160MxYUIwUlIyAAAGBnqYO7c9Jk3y0LiLPBGRLiiwQigkJATGxtpdW8TQ0BDu7u44cuSIdAq8Wq3GkSNHMGbMmCz9a9SogatXr2q0TZ8+HYmJiVixYgVHeoje4tKlaIwYcVB6XL16WWzf3guNGjnImIqISD5aF0I9e/bUeCyEwJMnT3DhwgXMmDFD6wATJ06En58fGjdujKZNm2L58uVITk7G4MGDAQADBw6Eo6Mj5s+fD2NjY9SpU0djfWtrawDI0k5EWTVq5ICJE5tj6dK/MHJkYyxe3AmmpgZvX5GIqJTSuhCysrLSeKynp4fq1avjq6++QqdOnbQO4OPjg2fPnmHmzJmIjo5GgwYNEBQUJE2gvn//PvT08n2WP5FOS0vLgKGhUuNMz3nzOqBz5yp47z23XNYkItINWl1QUaVS4fTp06hbty5sbGwKM1eh4QUVSVdcvRqDfv32YuTIxhg1qonccYiI3kmxuKCiUqlEp06dStdd5hVKuRMQFSi1WmDFir/QpMkGXLv2FJMm/Y4bN57JHYuIqFjS+tBYnTp1EBkZCRcXl8LIU/QMTOVOQFRgnjxJxODB+xEcfEdqq1q1TC5rEBHpNq0n33zzzTeYPHkyDhw4gCdPniAhIUHjp8TRZyFEpcP+/bdQr95ajSJowoTmOHduGGrVKidjMiKi4ivPI0JfffUVJk2ahC5dugAAunXrpjEBM/OmjCqVKqdNFE8cEaISLjk5HZMm/Y5160KlNgcHcwQEeKNTJ06IJiLKTZ4LoTlz5mDEiBE4evRoYeYpevomcicgyreIiOfo2vV/iIh4LrV5e9fAhg1dYWvLIp+I6G3yXAhlnlzm6elZaGFkwUNjVIKVL2+G9PQ3o7CmpgZYsaIzhgxpyLvFExHlkVZzhErlP648NEYlmJWVMX76qQeaNXPEpUvDMXRoo9L5OSUiKiRanTVWrVq1t/4j++LFi3cKVOR4aIxKkN27r6N584pwcvrnwqYtW1ZCSMgQFkBERPmgVSE0Z86cLFeWLvF4aIxKgISENIwb9xs2b76Mtm2dcfiwL5TKfwZ0WQQREeWPVoVQ3759YWdnV1hZ5MFDY1TMhYQ8wIAB+xAZGQcAOHYsCgcORKB79xoyJyMiKvnyPEeo1P7FyUNjVExlZKgxZ84xtG69SSqCLCwMsWWLN7p1qy5zOiKi0kHrs8ZKHY4IUTEUGRmHAQP2IiTkodTm4eGEn37qAReXknmfPyKi4ijPhZBarS7MHPLhHCEqRoQQ2Lr1CsaMOYTExHQAgFKpwMyZnpg6tTX09bW+GDwREeVC63uNlTo8NEbFyIULj+Hn94v02NXVBtu29UTz5hXlC0VEVIrxz0seGqNipEkTRwwf7g4AGDSoAcLChrMIIiIqRBwR4qExktHr1yro6+tpnIywZEkndOlSlROiiYiKAEeEOCJEMgkPj0Xz5j9i8+bLGu1mZoYsgoiIiggLIc4RoiImhMC6dRfQsOE6XLz4BGPH/obbt0vYFdmJiEoJHhrjoTEqQs+eJWPo0F8RGBgutTk6WiAl5bWMqYiIdBcLIR4aoyISHHwbgwbtR3R0ktQ2YoQ7lizxgqmpgYzJiIh0FwshHhqjQpaamoEpUw5j+fKzUputrSk2buyGrl05F4iISE66XQjpGQB6uv0WUOG6ffsFevbciatXn0ptnTtXwaZN3WFvby5jMiIiAnS9EOJhMSpkNjbGeP48BQBgZKTEokXvYcyYpqX33n1ERCWMbp81xsNiVMjKljVFQEB31K9fHhcufIqxY5uxCCIiKkZ0e0SIZ4xRAfv113A0aeKocdjrvffcEBrqAqVSt//uICIqjnT7X2YeGqMCkpycjhEjDqBbtx345JP9EEJoLGcRRERUPOn2v848NEYFIDT0MRo1Wo9160IBAL/9dhsHDkTInIqIiPJCxwshjghR/qlUaixYcArNm/+IiIjnAABTUwNs2NAVH35YTeZ0RESUF7o9R4iHxiifHjyIh6/vPhw/fk9qc3d3wPbtvVCtWlkZkxERkTZ0uxDioTHKh507r2HEiIN4+TIVAKBQAP7+rTB7dlsYGiplTkdERNrQ8UKII0Kknb/+eoi+ffdIj52cLLF1aw94ejrLF4qIiPJNt+cI8dAYaal584rw9a0HAPDxqY3Ll0ewCCIiKsF0fESIh8Yod2q1gJ6e5gUQv/++Cz74oCr69KnNiyMSEZVwuj0ixENjlIvIyDi0arURu3Zd12i3tDSCj08dFkFERKWAbo8I8dAYZUMIga1br2DMmENITEzHzZsH0KJFRTg5WckdjYiIChhHhIj+JS4uBX377oGf3y9ITEwHAJQpYyLdOJWIiEoX3R4R4hwh+pdjx6Lg67sPDx8mSG2DBjXAypWdYWFhJGMyIiIqLLpdCPHQGAFIT1dh5syjWLjwNDJvEWZtbYz16z9E79615Q1HRESFSrcLIR4a03mRkXHo3Xs3Ll58IrW1beuMLVu8OSeIiEgH6PgcIR4a03UmJvq4fz8eAGBgoIeFCzviyJGBLIKIiHSEbhdCPDSm8xwcLPDjj91Qo4Yt/vprKD7/vGWW6wYREVHpxUNjpFMOH45Ew4b2KFv2n33frVt1vP9+FRgY8D5hRES6RrdHhHhoTGekpmZgwoQgvPfeVgwffgAic1b0/2MRRESkm3S7EOKhMZ1w9WoMmjbdgOXLzwIA9uy5iaCg2zKnIiKi4kC3CyEeGivV1GqBFSv+QpMmG3D16lMAgJGREitXdkbnzlVkTkdERMWBjs8R4qGx0urJk0QMHrwfwcF3pLa6de2wfXsv1KljJ2MyIiIqTnS7EOKhsVIpMDAcQ4YEIjb2ldQ2YUJzzJvXAcbGuv0rT0REmnT7W0HJ2yaUNqdP30f37jukx/b25ti82RudOrnJmIqIiIor3Z0jpG8CKHi9mNLGw8MJPXrUAAB0714dV6+OZBFEREQ50t0RIc4PKhWEEFD8q6BVKBTYsKErunWrDj+/+hrLiIiI/kuHR4Q4P6ike/AgHu3bb8GBAxEa7WXLmmLQoAYsgoiI6K10d0TIgCNCJdmuXdcxfPgBvHyZiuvXn+LKlZGwtzeXOxYREZUwOjwixEKoJEpISMOgQb/Ax+dnvHyZCgAwNtbH48eJMicjIqKSSHdHhJQshEqakJAH6N9/L+7efSm1+fjUxpo1H8DGhvuTiIi0p7uFEK8hVGJkZKjxzTcn8M03J6BSvblHmIWFIVat6oIBA+pxLhAREeWb7hZC+sZyJ6A8iIp6iX799iAk5KHU5uHhhJ9+6gEXFxsZkxERUWmgu3OE9AzkTkB5oKenwI0bzwAASqUCc+a0xfHjg1gEERFRgdDdQoiHU0qESpWssHbth3B1tcGpU59g5kxP6Ovr7q8tEREVLH6jULFy8uQ9JCSkabT17VsH16+PQvPmFWVKRUREpVWxKIRWrVoFZ2dnGBsbo1mzZjh37lyOfTds2IDWrVvDxsYGNjY26NixY679qWRIT1fB3/8wPD0DMHbsb1mW82apRERUGGQvhHbu3ImJEydi1qxZuHjxIurXrw8vLy88ffo02/7Hjh3Dxx9/jKNHjyIkJAROTk7o1KkTHj16VMTJqaCEh8eiRYsfsWDBaQgBbNlyGb//fkfuWEREpAMUQgghZ4BmzZqhSZMm+P777wEAarUaTk5OGDt2LPz9/d+6vkqlgo2NDb7//nsMHDjwrf0TEhJgZWWF+B3dYenzy7vGp3cghMD69aGYMCEYKSkZAAADAz3MndsekyZ5QE+P87iIiOgN6fs7Ph6WlpYFtl1Zjzekp6cjNDQUU6ZMkdr09PTQsWNHhISE5Gkbr169wuvXr1GmTJlsl6elpSEt7Z85JwkJCe8WmgrEs2fJGDr0VwQGhktt1auXxfbtvdCokYOMyYiISJfIemgsNjYWKpUK5cuX12gvX748oqOj87SNL7/8EhUqVEDHjh2zXT5//nxYWVlJP05OTu+cm95NcPBt1Ku3VqMIGjmyMS5eHM4iiIiIipTsc4TexbfffosdO3Zg3759MDbO/gKJU6ZMQXx8vPTz4MGDIk5J/3by5D107rwN0dFJAABbW1MEBvbF6tUfwNSU13YiIqKiJeuhMVtbWyiVSsTExGi0x8TEwN7ePtd1Fy9ejG+//RaHDx9GvXr1cuxnZGQEIyOjAslL765Vq0ro3LkKgoJuo3PnKti0qTvvGk9ERLKRdUTI0NAQ7u7uOHLkiNSmVqtx5MgRtGjRIsf1Fi5ciK+//hpBQUFo3LhxUUSlAqJQKLBpU3esXt0Fhw71YxFERESykv3Q2MSJE7FhwwZs3rwZN2/exMiRI5GcnIzBgwcDAAYOHKgxmXrBggWYMWMGNm7cCGdnZ0RHRyM6OhpJSUlyvQTKQXR0Ej74YDuOHInUaLe3N8fIkU14s1QiIpKd7Fep8/HxwbNnzzBz5kxER0ejQYMGCAoKkiZQ379/H3p6/9Rra9asQXp6Oj766CON7cyaNQuzZ88uyuiUi8DAcAwZEojY2Fe4fDkaly+PQNmypnLHIiIi0iD7dYSKGq8jVLiSk9MxadLvWLcuVGpzcDDHr79+DHf3CjImIyKikqxUXkeISpfQ0Mfo338vwsOfS23e3jWwYUNX2NpyNIiIiIofFkL0zlQqNRYvPoPp048iI0MNADA1NcCKFZ0xZEhDzgUiIqJii4UQvZOHDxPg67sPx45FSW3u7g7Yvr0XqlUrK18wIiKiPJD9rDEq2VJSXuP8+Tc3vFUogClTWuHMmSEsgoiIqERgIUTvpGrVsli58n04OVni6FE/zJvXAYaGSrljERER5QkLIdLKuXOP8OrVa422wYMb4MaN0fD0dJYnFBERUT6xEKI8ychQY86cY/Dw+BGTJ/+usUyhUMDc3FCmZERERPnHQojeKjIyDm3abMLs2cehUgmsWXMBR4/elTsWERHRO+NZY5QjIQS2br2CMWMOITExHQCgVCowc6YnWreuLHM6IiKid8dCiLIVF5eCkSMPYufO61Kbq6sNtm3riebNK8qYjIiIqOCwEKIsjh+Pgq/vPjx4kCC1DRrUACtXdoaFhZGMyYiIiAoWCyHScPx4FNq124zMO9DZ2Bhj3boP0bt3bXmDERERFQJOliYNrVpVQps2b+b/tGvnjCtXRrIIIiKiUosjQqRBqdTD1q09sHv3DYwf3xx6erxPGBERlV4cEdJhz54lo1evXTh9+r5Gu5OTFSZObMEiiIiISj2OCOmo4ODbGDRoP6Kjk3Dx4hNcvjwClpacCE1ERLqFI0I6JjU1A+PHB6Fz522Ijk4CACQlpSMi4rnMyYiIiIoeR4R0yNWrMejXby+uXXsqtXXuXAWbNnWHvb25jMmIiIjkwUJIB6jVAt99dxZffnkYaWkqAICRkRKLFr2HMWOaQqHgXCAiItJNLIRKuSdPEjF48H4EB9+R2urWtcP27b1Qp46djMmIiIjkxzlCpdyLFyk4dixKejxhQnOcOzeMRRARERFYCJV6tWvbYdGi92Bvb47g4AFYutQLxsYcCCQiIgJYCJU6ly9HIy0tQ6NtzJimuHFjFDp1cpMpFRERUfHEQqiUUKnUWLDgFBo33oBp0/7UWKZQKGBjYyJTMiIiouKLhVAp8OBBPDp02AJ//yPIyFBjyZIQnDp1/+0rEhER6ThOFinhdu26juHDD+Dly1QAgEIB+Pu3QtOmjjInIyIiKv5YCJVQCQlpGDfuN2zefFlqc3KyxNatPeDp6SxfMCIiohKEhVAJFBLyAAMG7ENkZJzU5uNTG2vWfMC5QERERFpgIVTCHDsWhY4dt0ClEgAACwtDrFrVBQMG1OMVoomIiLTEydIlTMuWTnB3rwAA8PBwwuXLI+DrW59FEBERUT5wRKiEMTBQYtu2nti58xq+/LIV9PVZyxIREeUXC6FiLC4uBWPG/IaJE5tLo0AAUKVKGUyb1kbGZEQlgxACGRkZUKlUckchojwwMDCAUqks0udkIVRMHTsWBV/ffXj4MAGhoY9x8eJwmJoayB2LqMRIT0/HkydP8OrVK7mjEFEeKRQKVKxYEebm5kX2nCyEipn0dBVmzjyKhQtPQ7yZD42nT5Nx/fpTNGnCawMR5YVarcbdu3ehVCpRoUIFGBoach4dUTEnhMCzZ8/w8OFDVK1atchGhlgIFSPh4bHo128vLl58IrW1a+eMLVt6oGJFSxmTEZUs6enpUKvVcHJygqmpqdxxiCiPypUrh6ioKLx+/ZqFkC4RQmD9+lBMmBCMlJQ3N0w1MNDD3LntMWmSB/T0+JcsUX7o6fFkAqKSRI6RWxZCMnv2LBlDh/6KwMBwqa169bLYvr0XGjVykDEZERFR6cdCSGYPHiTg0KG/pccjRzbG4sWdODGaiIioCHDcWGaNGjngm2/awdbWFIGBfbF69QcsgoiI8iE8PBz29vZITEyUOwpl48aNG6hYsSKSk5PljqKBhVARu3UrFq9fa17TZPJkD1y/Pgpdu1aXKRURFReDBg2CQqGAQqGAgYEBXFxc8MUXXyA1NTVL3wMHDsDT0xMWFhYwNTVFkyZNEBAQkO129+zZg7Zt28LKygrm5uaoV68evvrqK7x48aKQX1HRmTJlCsaOHQsLCwu5oxSaVatWwdnZGcbGxmjWrBnOnTuXa//Xr1/jq6++gpubG4yNjVG/fn0EBQVp9FGpVJgxYwZcXFxgYmICNzc3fP311xCZpy4D0u/kf38WLVok9YmIiED37t1ha2sLS0tLtGrVCkePHpWW16pVC82bN8fSpUsL6N0oIELHxMfHCwAifkf3In1elUotli8PEUZGX4uZM/8s0ucm0jUpKSnixo0bIiUlRe4oWvPz8xOdO3cWT548Effv3xf79u0TlpaW4osvvtDot3LlSqGnpyemTJkirl+/Lv7++2+xePFiYWRkJCZNmqTRd+rUqUKpVIrJkyeL06dPi7t374rff/9d9OzZUyxfvrzIXltaWlqhbfvevXvCwMBAPHz48J22U5gZ39WOHTuEoaGh2Lhxo7h+/boYNmyYsLa2FjExMTmu88UXX4gKFSqIgwcPijt37ojVq1cLY2NjcfHiRanP3LlzRdmyZcWBAwfE3bt3xe7du4W5ublYsWKF1OfJkycaPxs3bhQKhULcuXNH6lO1alXRpUsXcfnyZRERESFGjRolTE1NxZMnT6Q+Bw4cEA4ODuL169fZ5s3tsyt9f8fHa/W+vQ0LoSLw+HGC8PLaKoDZApgt9PTmiLNn3+3DSkQ5K+mFUPfu3TXaevbsKRo2bCg9vn//vjAwMBATJ07Msv7KlSsFAPHXX38JIYQ4e/asAJBjwRMXF5djlgcPHoi+ffsKGxsbYWpqKtzd3aXtZpfzs88+E56entJjT09PMXr0aPHZZ5+JsmXLirZt24qPP/5Y9OnTR2O99PR0UbZsWbF582YhhBAqlUrMmzdPODs7C2NjY1GvXj2xe/fuHHMKIcSiRYtE48aNNdpiY2NF3759RYUKFYSJiYmoU6eO2L59u0af7DIKIcTVq1dF586dhZmZmbCzsxMDBgwQz549k9b77bffRMuWLYWVlZUoU6aM+OCDD8Tt27dzzfiumjZtKkaPHi09VqlUokKFCmL+/Pk5ruPg4CC+//57jbaePXuK/v37S48/+OAD8cknn+Ta57+6d+8u2rdvLz1+9uyZACBOnDghtSUkJAgA4o8//pDa0tLShJGRkTh8+HC225WjEOJk6UK2f/8tDB36K2Jj/7m67bhxTVGvXnkZUxHpqJ8aA8nRRf+8ZvbAgAv5WvXatWs4c+YMKleuLLX9/PPPeP36NSZPnpyl//DhwzF16lT873//Q7NmzbBt2zaYm5tj1KhR2W7f2to62/akpCR4enrC0dERgYGBsLe3x8WLF6FWq7XKv3nzZowcORKnT58GANy+fRu9e/dGUlKSdPXg4OBgvHr1Cj169AAAzJ8/Hz/99BPWrl2LqlWr4sSJExgwYADKlSsHT0/PbJ/n5MmTaNy4sUZbamoq3N3d8eWXX8LS0hIHDx6Er68v3Nzc0LRp0xwzvnz5Eu3bt8fQoUOxbNkypKSk4Msvv0SfPn3w559/AgCSk5MxceJE1KtXD0lJSZg5cyZ69OiBsLCwHC/bMG/ePMybNy/X9+vGjRuoVKlSlvb09HSEhoZiypQpUpuenh46duyIkJCQHLeXlpYGY2NjjTYTExOcOnVKeuzh4YH169cjIiIC1apVw+XLl3Hq1KkcD2HFxMTg4MGD2Lx5s9RWtmxZVK9eHVu2bEGjRo1gZGSEdevWwc7ODu7u7lI/Q0NDNGjQACdPnkSHDh1yfS+KCguhQpKcnI5Jk37HunWhUpu9vTk2b/ZGp05uMiYj0mHJ0UDSI7lTvNWBAwdgbm6OjIwMpKWlQU9PD99//720PCIiAlZWVnBwyHqJDUNDQ7i6uiIiIgIA8Pfff8PV1RUGBtqdhLF9+3Y8e/YM58+fR5kyZQAAVapU0fq1VK1aFQsXLpQeu7m5wczMDPv27YOvr6/0XN26dYOFhQXS0tIwb948HD58GC1atAAAuLq64tSpU1i3bl2OhdC9e/eyFEKOjo4axeLYsWMRHByMXbt2aRRC/834zTffoGHDhhpFy8aNG+Hk5CQVC7169dJ4ro0bN6JcuXK4ceMG6tSpk23GESNGoE+fPrm+XxUqVMi2PTY2FiqVCuXLa/4RXb58edy6dSvH7Xl5eWHp0qVo06YN3NzccOTIEezdu1fj/nv+/v5ISEhAjRo1oFQqoVKpMHfuXPTv3z/bbW7evBkWFhbo2bOn1KZQKHD48GF4e3vDwsICenp6sLOzQ1BQEGxsbLK8xnv37uX6PhQlFkKFIDT0Mfr124uIiOdSW/fu1fHDD91ga8ur3BLJxsy+RDxvu3btsGbNGiQnJ2PZsmXQ19fP8sWbV+JfE161ERYWhoYNG0pFUH79ezQAAPT19dGnTx9s27YNvr6+SE5Oxv79+7Fjxw4Ab0aMXr16hffee09jvfT0dDRs2DDH50lJScky8qFSqTBv3jzs2rULjx49Qnp6OtLS0rJcbfy/GS9fvoyjR49me7+rO3fuoFq1avj7778xc+ZMnD17FrGxsdJI2f3793MshMqUKfPO76e2VqxYgWHDhqFGjRpQKBRwc3PD4MGDsXHjRqnPrl27sG3bNmzfvh21a9dGWFgYxo8fjwoVKsDPzy/LNjdu3Ij+/ftrvN9CCIwePRp2dnY4efIkTExM8MMPP6Br1644f/68RtFuYmJSrO4ByEKogP355114ef2EjIw3HwpTUwMsX+6FoUMb8V5HRHLL5+GpomZmZiaNvmzcuBH169fHjz/+iCFDhgAAqlWrhvj4eDx+/DjLCEJ6ejru3LmDdu3aSX1PnTqF169fazUqZGJikutyPT29LEXW69evs30t/9W/f394enri6dOn+OOPP2BiYoLOnTsDeHNIDgAOHjwIR0fN+ysaGRnlmMfW1hZxcXEabYsWLcKKFSuwfPly1K1bF2ZmZhg/fjzS09NzzZiUlISuXbtiwYIFWZ4n8wu9a9euqFy5MjZs2IAKFSpArVajTp06Wbb9b+9yaMzW1hZKpRIxMTEa7TExMbC3z7nQLleuHH755Rekpqbi+fPnqFChAvz9/eHq6ir1+fzzz+Hv74++ffsCAOrWrYt79+5h/vz5WQqhkydPIjw8HDt37tRo//PPP3HgwAHExcXB0vLNLaFWr16NP/74A5s3b4a/v7/U98WLF3BzKz5HRnj6fAFr2dIJtWqVAwC4uzvg0qXhGDbMnUUQEeWLnp4epk6diunTpyMlJQUA0KtXLxgYGGDJkiVZ+q9duxbJycn4+OOPAQD9+vVDUlISVq9ene32X758mW17vXr1EBYWluPp9eXKlcOTJ0802sLCwvL0mjw8PODk5ISdO3di27Zt6N27t1Sk1apVC0ZGRrh//z6qVKmi8ePk5JTjNhs2bIgbN25otJ0+fRrdu3fHgAEDUL9+fY1Dhrlp1KgRrl+/Dmdn5ywZzMzM8Pz5c4SHh2P69Ono0KEDatasmaUIy86IESMQFhaW609Oh8YMDQ3h7u6OI0eOSG1qtRpHjhyRDiHmxtjYGI6OjsjIyMCePXvQvXt3admrV6+yzGtSKpXZzgf78ccf4e7ujvr162u0Z47w/Hc7enp6WbZz7dq1XEf3ilyBTr0uAYrirLFr12LEtGlHRFpaRqE9BxHlrLSdNfb69Wvh6OgoFi1aJLUtW7ZM6OnpialTp4qbN2+K27dviyVLlmR7+vwXX3whlEql+Pzzz8WZM2dEVFSUOHz4sPjoo49yPJssLS1NVKtWTbRu3VqcOnVK3LlzR/z888/izJkzQgghgoKChEKhEJs3bxYRERFi5syZwtLSMstZY5999lm22582bZqoVauW0NfXFydPnsyyrGzZsiIgIEDcvn1bhIaGipUrV4qAgIAc37fAwEBhZ2cnMjL++Xd3woQJwsnJSZw+fVrcuHFDDB06VFhaWmq8v9llfPTokShXrpz46KOPxLlz58Tt27dFUFCQGDRokMjIyBAqlUqULVtWDBgwQPz999/iyJEjokmTJgKA2LdvX44Z39WOHTuEkZGRCAgIEDdu3BCffvqpsLa2FtHR0VIfX19f4e/vLz3+66+/xJ49e8SdO3fEiRMnRPv27YWLi4vG2YJ+fn7C0dFROn1+7969wtbWNsslG+Lj44WpqalYs2ZNlmzPnj0TZcuWFT179hRhYWEiPDxcTJ48WRgYGIiwsDCp3927d4VCoRBRUVHZvkaePl8ECrIQio9PFUOH7hfXruV8DQciKnqlrRASQoj58+eLcuXKiaSkJKlt//79onXr1sLMzEwYGxsLd3d3sXHjxmy3u3PnTtGmTRthYWEhzMzMRL169cRXX32V6+nzUVFRolevXsLS0lKYmpqKxo0bi7Nnz0rLZ86cKcqXLy+srKzEhAkTxJgxY/JcCN24cUMAEJUrVxZqtVpjmVqtFsuXLxfVq1cXBgYGoly5csLLy0scP348x6yvX78WFSpUEEFBQVLb8+fPRffu3YW5ubmws7MT06dPFwMHDnxrISSEEBEREaJHjx7C2tpamJiYiBo1aojx48dLWf/44w9Rs2ZNYWRkJOrVqyeOHTtW6IWQEEJ89913olKlSsLQ0FA0bdpUupzBv1+Pn5+f9PjYsWNSzrJlywpfX1/x6NEjjXUSEhLEZ599JipVqiSMjY2Fq6urmDZtWpZrKq1bt06YmJiIly9fZpvt/PnzolOnTqJMmTLCwsJCNG/eXBw6dEijz7x584SXl1eOr0+OQkghRD5n0pVQCQkJsLKyQvyO7rD0+SXf2wkJeYABA/YhMjIO9eqVx7lzQ2FkxClXRMVBamoq7t69CxcXlywTaKn0WrVqFQIDAxEcHCx3FMpGeno6qlatiu3bt6Nly5bZ9sntsyt9f8fHS/OQCgLnCGkpI0ONOXOOoXXrTYiMfHNM+O7dOFy5EvOWNYmIqDANHz4cbdq04b3Giqn79+9j6tSpORZBcuEQhhYiI+MwYMBehIQ8lNo8PJzw00894OJik8uaRERU2PT19TFt2jS5Y1AOMiecFzcshPJACIGtW69gzJhDSEx8c2qkUqnAzJmemDq1NfT1ObBGRERUErEQeou4uBSMHHkQO3del9pcXW2wbVtPNG9eUcZkRERE9K5YCL3FzZux2L37n2tTDBrUACtXdoaFRc4X9iKi4kHHzgUhKvHk+MzymM5beHg4Ydq01rC2NsauXR9h06buLIKIirnMi/MVp8v4E9HbZV6ZW6lUFtlzckToP+7ejUOlSlZQKv+pEWfMaIPhw93h6Fhwp+sRUeFRKpWwtrbG06dPAQCmpqa8ujtRMadWq/Hs2TOYmppCX7/oyhMWQv9PCIH160MxYUIwZs3yxJdftpKWGRgoWQQRlTCZ91/KLIaIqPjT09NDpUqVivQPFxZCAJ49S8bQob8iMDAcADB9+lF06uSGhg0d3rImERVXCoUCDg4OsLOzy/ZmoERU/BgaGma5X1lhKxaF0KpVq7Bo0SJER0ejfv36+O6779C0adMc++/evRszZsxAVFQUqlatigULFqBLly75eu7g4NsYNGg/oqOTpLahQxuienXbfG2PiIoXpVJZpPMNiKhkkX2y9M6dOzFx4kTMmjULFy9eRP369eHl5ZXjcPaZM2fw8ccfY8iQIbh06RK8vb3h7e2Na9euafW8qekKjB8fhM6dt0lFkK2tKQID+2LNmg9hamrwzq+NiIiIijfZ7zXWrFkzNGnSBN9//z2AN5OlnJycMHbsWPj7+2fp7+Pjg+TkZBw4cEBqa968ORo0aIC1a9e+9fky71VS02kCbj6wkto7d66CTZu6w97evABeFRERERWkUnmvsfT0dISGhqJjx45Sm56eHjp27IiQkJBs1wkJCdHoDwBeXl459s/JzQdvToE3MlJi5crOOHSoH4sgIiIiHSPrHKHY2FioVCqUL19eo718+fK4detWtutER0dn2z86Ojrb/mlpaUhLS5Mex8fHZy5BrVrl8OOP3VGrVjnepI+IiKgYS0hIAFDwF10sFpOlC9P8+fMxZ86cbJYsw40bQIsWk4o8ExEREeXP8+fPYWVl9faOeSRrIWRrawulUomYmBiN9piYGOkaIP9lb2+vVf8pU6Zg4sSJ0uOXL1+icuXKuH//foG+kaS9hIQEODk54cGDBwV6vJfyh/uj+OC+KD64L4qP+Ph4VKpUCWXKlCnQ7cpaCBkaGsLd3R1HjhyBt7c3gDeTpY8cOYIxY8Zku06LFi1w5MgRjB8/Xmr7448/0KJFi2z7GxkZwcgo6y0xrKys+EtdTFhaWnJfFCPcH8UH90XxwX1RfBT0dYZkPzQ2ceJE+Pn5oXHjxmjatCmWL1+O5ORkDB48GAAwcOBAODo6Yv78+QCAzz77DJ6enliyZAk++OAD7NixAxcuXMD69evlfBlERERUAsleCPn4+ODZs2eYOXMmoqOj0aBBAwQFBUkTou/fv69R/Xl4eGD79u2YPn06pk6diqpVq+KXX35BnTp15HoJREREVELJXggBwJgxY3I8FHbs2LEsbb1790bv3r3z9VxGRkaYNWtWtofLqGhxXxQv3B/FB/dF8cF9UXwU1r6Q/YKKRERERHKR/RYbRERERHJhIUREREQ6i4UQERER6SwWQkRERKSzSmUhtGrVKjg7O8PY2BjNmjXDuXPncu2/e/du1KhRA8bGxqhbty4OHTpURElLP232xYYNG9C6dWvY2NjAxsYGHTt2fOu+I+1o+9nItGPHDigUCunCp/TutN0XL1++xOjRo+Hg4AAjIyNUq1aN/1YVEG33xfLly1G9enWYmJjAyckJEyZMQGpqahGlLb1OnDiBrl27okKFClAoFPjll1/eus6xY8fQqFEjGBkZoUqVKggICND+iUUps2PHDmFoaCg2btworl+/LoYNGyasra1FTExMtv1Pnz4tlEqlWLhwobhx44aYPn26MDAwEFevXi3i5KWPtvuiX79+YtWqVeLSpUvi5s2bYtCgQcLKyko8fPiwiJOXTtruj0x3794Vjo6OonXr1qJ79+5FE7aU03ZfpKWlicaNG4suXbqIU6dOibt374pjx46JsLCwIk5e+mi7L7Zt2yaMjIzEtm3bxN27d0VwcLBwcHAQEyZMKOLkpc+hQ4fEtGnTxN69ewUAsW/fvlz7R0ZGClNTUzFx4kRx48YN8d133wmlUimCgoK0et5SVwg1bdpUjB49WnqsUqlEhQoVxPz587Pt36dPH/HBBx9otDVr1kwMHz68UHPqAm33xX9lZGQICwsLsXnz5sKKqFPysz8yMjKEh4eH+OGHH4Sfnx8LoQKi7b5Ys2aNcHV1Fenp6UUVUWdouy9Gjx4t2rdvr9E2ceJE0bJly0LNqWvyUgh98cUXonbt2hptPj4+wsvLS6vnKlWHxtLT0xEaGoqOHTtKbXp6eujYsSNCQkKyXSckJESjPwB4eXnl2J/yJj/74r9evXqF169fF/gN9nRRfvfHV199BTs7OwwZMqQoYuqE/OyLwMBAtGjRAqNHj0b58uVRp04dzJs3DyqVqqhil0r52RceHh4IDQ2VDp9FRkbi0KFD6NKlS5Fkpn8U1Pd3sbiydEGJjY2FSqWSbs+RqXz58rh161a260RHR2fbPzo6utBy6oL87Iv/+vLLL1GhQoUsv+ikvfzsj1OnTuHHH39EWFhYESTUHfnZF5GRkfjzzz/Rv39/HDp0CLdv38aoUaPw+vVrzJo1qyhil0r52Rf9+vVDbGwsWrVqBSEEMjIyMGLECEydOrUoItO/5PT9nZCQgJSUFJiYmORpO6VqRIhKj2+//RY7duzAvn37YGxsLHccnZOYmAhfX19s2LABtra2csfReWq1GnZ2dli/fj3c3d3h4+ODadOmYe3atXJH0znHjh3DvHnzsHr1aly8eBF79+7FwYMH8fXXX8sdjfKpVI0I2draQqlUIiYmRqM9JiYG9vb22a5jb2+vVX/Km/zsi0yLFy/Gt99+i8OHD6NevXqFGVNnaLs/7ty5g6ioKHTt2lVqU6vVAAB9fX2Eh4fDzc2tcEOXUvn5bDg4OMDAwABKpVJqq1mzJqKjo5Geng5DQ8NCzVxa5WdfzJgxA76+vhg6dCgAoG7dukhOTsann36KadOmadwknApXTt/flpaWeR4NAkrZiJChoSHc3d1x5MgRqU2tVuPIkSNo0aJFtuu0aNFCoz8A/PHHHzn2p7zJz74AgIULF+Lrr79GUFAQGjduXBRRdYK2+6NGjRq4evUqwsLCpJ9u3bqhXbt2CAsLg5OTU1HGL1Xy89lo2bIlbt++LRWjABAREQEHBwcWQe8gP/vi1atXWYqdzAJV8NadRarAvr+1m8dd/O3YsUMYGRmJgIAAcePGDfHpp58Ka2trER0dLYQQwtfXV/j7+0v9T58+LfT19cXixYvFzZs3xaxZs3j6fAHRdl98++23wtDQUPz888/iyZMn0k9iYqJcL6FU0XZ//BfPGis42u6L+/fvCwsLCzFmzBgRHh4uDhw4IOzs7MQ333wj10soNbTdF7NmzRIWFhbif//7n4iMjBS///67cHNzE3369JHrJZQaiYmJ4tKlS+LSpUsCgFi6dKm4dOmSuHfvnhBCCH9/f+Hr6yv1zzx9/vPPPxc3b94Uq1at4unzmb777jtRqVIlYWhoKJo2bSr++usvaZmnp6fw8/PT6L9r1y5RrVo1YWhoKGrXri0OHjxYxIlLL232ReXKlQWALD+zZs0q+uCllLafjX9jIVSwtN0XZ86cEc2aNRNGRkbC1dVVzJ07V2RkZBRx6tJJm33x+vVrMXv2bOHm5iaMjY2Fk5OTGDVqlIiLiyv64KXM0aNHs/0OyHz//fz8hKenZ5Z1GjRoIAwNDYWrq6vYtGmT1s+rEIJjeURERKSbStUcISIiIiJtsBAiIiIincVCiIiIiHQWCyEiIiLSWSyEiIiISGexECIiIiKdxUKIiIiIdBYLISLSEBAQAGtra7lj5JtCocAvv/ySa59BgwbB29u7SPIQUfHGQoioFBo0aBAUCkWWn9u3b8sdDQEBAVIePT09VKxYEYMHD8bTp08LZPtPnjzB+++/DwCIioqCQqFAWFiYRp8VK1YgICCgQJ4vJ7Nnz5Zep1KphJOTEz799FO8ePFCq+2waCMqXKXq7vNE9I/OnTtj06ZNGm3lypWTKY0mS0tLhIeHQ61W4/Llyxg8eDAeP36M4ODgd952TncN/zcrK6t3fp68qF27Ng4fPgyVSoWbN2/ik08+QXx8PHbu3Fkkz09Eb8cRIaJSysjICPb29ho/SqUSS5cuRd26dWFmZgYnJyeMGjUKSUlJOW7n8uXLaNeuHSwsLGBpaQl3d3dcuHBBWn7q1Cm0bt0aJiYmcHJywrhx45CcnJxrNoVCAXt7e1SoUAHvv/8+xo0bh8OHDyMlJQVqtRpfffUVKlasCCMjIzRo0ABBQUHSuunp6RgzZgwcHBxgbGyMypUrY/78+Rrbzjw05uLiAgBo2LAhFAoF2rZtC0BzlGX9+vWoUKGCxp3dAaB79+745JNPpMf79+9Ho0aNYGxsDFdXV8yZMwcZGRm5vk59fX3Y29vD0dERHTt2RO/evfHHH39Iy1UqFYYMGQIXFxeYmJigevXqWLFihbR89uzZ2Lx5M/bv3y+NLh07dgwA8ODBA/Tp0wfW1tYoU6YMunfvjqioqFzzEFFWLISIdIyenh5WrlyJ69evY/Pmzfjzzz/xxRdf5Ni/f//+qFixIs6fP4/Q0FD4+/vDwMAAAHDnzh107twZvXr1wpUrV7Bz506cOnUKY8aM0SqTiYkJ1Go1MjIysGLFCixZsgSLFy/GlStX4OXlhW7duuHvv/8GAKxcuRKBgYHYtWsXwsPDsW3bNjg7O2e73XPnzgEADh8+jCdPnmDv3r1Z+vTu3RvPnz/H0aNHpbYXL14gKCgI/fv3BwCcPHkSAwcOxGeffYYbN25g3bp1CAgIwNy5c/P8GqOiohAcHAxDQ0OpTa1Wo2LFiti9ezdu3LiBmTNnYurUqdi1axcAYPLkyejTpw86d+6MJ0+e4MmTJ/Dw8MDr16/h5eUFCwsLnDx5EqdPn4a5uTk6d+6M9PT0PGciIqBU3n2eSNf5+fkJpVIpzMzMpJ+PPvoo2767d+8WZcuWlR5v2rRJWFlZSY8tLCxEQEBAtusOGTJEfPrppxptJ0+eFHp6eiIlJSXbdf67/YiICFGtWjXRuHFjIYQQFSpUEHPnztVYp0mTJmLUqFFCCCHGjh0r2rdvL9RqdbbbByD27dsnhBDi7t27AoC4dOmSRh8/Pz/RvXt36XH37t3FJ598Ij1et26dqFChglCpVEIIITp06CDmzZunsY2tW7cKBweHbDMIIcSsWbOEnp6eMDMzE8bGxtKdtJcuXZrjOkIIMXr0aNGrV68cs2Y+d/Xq1TXeg7S0NGFiYiKCg4Nz3T4RaeIcIaJSql27dlizZo302MzMDMCb0ZH58+fj1q1bSEhIQEZGBlJTU/Hq1SuYmppm2c7EiRMxdOhQbN26VTq84+bmBuDNYbMrV65g27ZtUn8hBNRqNe7evYuaNWtmmy0+Ph7m5uZQq9VITU1Fq1at8MMPPyAhIQGPHz9Gy5YtNfq3bNkSly9fBvDmsNZ7772H6tWro3Pnzvjwww/RqVOnd3qv+vfvj2HDhmH16tUwMjLCtm3b0LdvX+jp6Umv8/Tp0xojQCqVKtf3DQCqV6+OwMBApKam4qeffkJYWBjGjh2r0WfVqlXYuHEj7t+/j5SUFKSnp6NBgwa55r18+TJu374NCwsLjfbU1FTcuXMnH+8Ake5iIURUSpmZmaFKlSoabVFRUfjwww8xcuRIzJ07F2XKlMGpU6cwZMgQpKenZ/uFPnv2bPTr1w8HDx7Eb7/9hlmzZmHHjh3o0aMHkpKSMHz4cIwbNy7LepUqVcoxm4WFBS5evAg9PT04ODjAxMQEAJCQkPDW19WoUSPcvXsXv/32Gw4fPow+ffqgY8eO+Pnnn9+6bk66du0KIQQOHjyIJk2a4OTJk1i2bJm0PCkpCXPmzEHPnj2zrGtsbJzjdg0NDaV98O233+KDDz7AnDlz8PXXXwMAduzYgcmTJ2PJkiVo0aIFLCwssGjRIpw9ezbXvElJSXB3d9coQDMVlwnxRCUFCyEiHRIaGgq1Wo0lS5ZIox2Z81FyU61aNVSrVg0TJkzAxx9/jE2bNqFHjx5o1KgRbty4kaXgehs9Pb1s17G0tESFChVw+vRpeHp6Su2nT59G06ZNNfr5+PjAx8cHH330ETp37owXL16gTJkyGtvLnI+jUqlyzWNsbIyePXti27ZtuH37NqpXr45GjRpJyxs1aoTw8HCtX+d/TZ8+He3bt8fIkSOl1+nh4YFRo0ZJff47omNoaJglf6NGjbBz507Y2dnB0tLynTIR6TpOlibSIVWqVMHr16/x3XffITIyElu3bsXatWtz7J+SkoIxY8bg2LFjuHfvHk6fPo3z589Lh7y+/PJLnDlzBmPGjEFYWBj+/vtv7N+/X+vJ0v/2+eefY8GCBdi5cyfCw8Ph7++PsLAwfPbZZwCApUuX4n//+x9u3bqFiIgI7N69G/b29tleBNLOzg4mJiYICgpCTEwM4uPjc3ze/v374+DBg9i4caM0STrTzJkzsWXLFsyZMwfXr1/HzZs3sWPHDkyfPl2r19aiRQvUq1cP8+bNAwBUrVoVFy5cQHBwMCIiIjBjxgycP39eYx1nZ2dcuXIF4eHhiI2NxevXr9G/f3/Y2tqie/fuOHnyJO7evYtjx45h3LhxePjwoVaZiHSe3JOUiKjgZTfBNtPSpUuFg4ODMDExEV5eXmLLli0CgIiLixNCaE5mTktLE3379hVOTk7C0NBQVKhQQYwZM0ZjIvS5c+fEe++9J8zNzYWZmZmoV69elsnO//bfydL/pVKpxOzZs4Wjo6MwMDAQ9evXF7/99pu0fP369aJBgwbCzMxMWFpaig4dOoiLFy9Ky/GvydJCCLFhwwbh5OQk9PT0hKenZ47vj0qlEg4ODgKAuHPnTpZcQUFBwsPDQ5iYmAhLS0vRtGlTsX79+hxfx6xZs0T9+vWztP/vf/8TRkZG4v79+yI1NVUMGjRIWFlZCWtrazFy5Ejh7++vsd7Tp0+l9xeAOHr0qBBCiCdPnoiBAwcKW1tbYWRkJFxdXcWwYcNEfHx8jpmIKCuFEELIW4oRERERyYOHxoiIiEhnsRAiIiIincVCiIiIiHQWCyEiIiLSWSyEiIiISGexECIiIiKdxUKIiIiIdBYLISIiItJZLISIiIhIZ7EQIiIiIp3FQoiIiIh0FgshIiIi0ln/By5lzACLWyFYAAAAAElFTkSuQmCC"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 2 Axes>","image/png":"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"},"metadata":{}},{"name":"stdout","text":"Test done in 0.0 m 3.7055022716522217 s \nTest loss: 0.69612, acc: 0.83654, npv: 0.99254, ppv: 0.79388, sen: 0.99744, spe: 0.56838, fos: 0.88409, fpr: 0.43162\n","output_type":"stream"}]}]}